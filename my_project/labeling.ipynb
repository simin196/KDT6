{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 모듈 로딩\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# 텐서 플로우 사용한거 >> 이건 걍 gpt로 pytorch로 변경\n",
    "import imantics\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir ='/kaggle/input/panoramic-dental-dataset/images_cut'\n",
    "masks_dir = '/kaggle/input/panoramic-dental-dataset/labels_cut'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_listdir = os.listdir(images_dir)\n",
    "masks_listdir = os.listdir(masks_dir)\n",
    "random_images = np.random.choice(images_listdir, size = 9, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(images_listdir))\n",
    "print(len(masks_listdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=512\n",
    "input_image_size=(512,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img, (image_size, image_size))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 3\n",
    "cols = 3\n",
    "fig, ax = plt.subplots(rows, cols, figsize = (10,10))\n",
    "for i, ax in enumerate(ax.flat):\n",
    "    if i < len(random_images):\n",
    "        img = read_image(f\"{images_dir}/{random_images[i]}\")\n",
    "        ax.set_title(f\"{random_images[i]}\")\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ground truth masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(rows, cols, figsize = (10,10))\n",
    "for i, ax in enumerate(ax.flat):\n",
    "    if i < len(random_images):\n",
    "        file=random_images[i]\n",
    "        if os.path.exists(os.path.join(masks_dir,file)):\n",
    "            img = read_image(f\"{masks_dir}/{file}\")\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            ax.set_title(f\"{random_images[i]}\")\n",
    "            ax.imshow(img)\n",
    "            ax.axis('off')\n",
    "        else:\n",
    "            print('not exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASKS=np.zeros((1,image_size, image_size, 1), dtype=bool)\n",
    "IMAGES=np.zeros((1,image_size, image_size, 3),dtype=np.uint8)\n",
    "\n",
    "for j,file in enumerate(images_listdir[0:number]):   ##the smaller, the faster\n",
    "    try:\n",
    "        image = read_image(f\"{images_dir}/{file}\")\n",
    "        image_ex = np.expand_dims(image, axis=0)\n",
    "        IMAGES = np.vstack([IMAGES, image_ex])\n",
    "        mask = read_image(f\"{masks_dir}/{file}\") \n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "        mask = mask.reshape(512,512,1)\n",
    "        mask_ex = np.expand_dims(mask, axis=0)    \n",
    "        MASKS = np.vstack([MASKS, mask_ex])\n",
    "    except:\n",
    "        print(file)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=np.array(IMAGES)[1:number+1]\n",
    "masks=np.array(MASKS)[1:number+1]\n",
    "print(images.shape,masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train, images_test, masks_train, masks_test = train_test_split(\n",
    "    images, masks, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(images_train), len(masks_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input, num_filters):\n",
    "    conv = tf.keras.layers.Conv2D(num_filters, 3, padding=\"same\")(input)\n",
    "    conv = tf.keras.layers.BatchNormalization()(conv)\n",
    "    conv = tf.keras.layers.Activation(\"relu\")(conv)\n",
    "    conv = tf.keras.layers.Conv2D(num_filters, 3, padding=\"same\")(conv)\n",
    "    conv = tf.keras.layers.BatchNormalization()(conv)\n",
    "    conv = tf.keras.layers.Activation(\"relu\")(conv)\n",
    "    return conv\n",
    "\n",
    "def encoder_block(input, num_filters):\n",
    "    skip = conv_block(input, num_filters)\n",
    "    pool = tf.keras.layers.MaxPool2D((2,2))(skip)\n",
    "    return skip, pool\n",
    "\n",
    "def decoder_block(input, skip, num_filters):\n",
    "    up_conv = tf.keras.layers.Conv2DTranspose(num_filters, (2,2), strides=2, padding=\"same\")(input)\n",
    "    conv = tf.keras.layers.Concatenate()([up_conv, skip])\n",
    "    conv = conv_block(conv, num_filters)\n",
    "    return conv\n",
    "\n",
    "def Unet(input_shape):\n",
    "    inputs = tf.keras.layers.Input(input_shape)\n",
    "\n",
    "    skip1, pool1 = encoder_block(inputs, 64)\n",
    "    skip2, pool2 = encoder_block(pool1, 128)\n",
    "    skip3, pool3 = encoder_block(pool2, 256)\n",
    "    skip4, pool4 = encoder_block(pool3, 512)\n",
    "\n",
    "    bridge = conv_block(pool4, 1024)\n",
    "\n",
    "    decode1 = decoder_block(bridge, skip4, 512)\n",
    "    decode2 = decoder_block(decode1, skip3, 256)\n",
    "    decode3 = decoder_block(decode2, skip2, 128)\n",
    "    decode4 = decoder_block(decode3, skip1, 64)\n",
    "    outputs = tf.keras.layers.Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(decode4)\n",
    "    model = tf.keras.models.Model(inputs, outputs, name=\"U-Net\")\n",
    "    return model\n",
    "\n",
    "unet_model = Unet((512,512,3))\n",
    "unet_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#unet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train\n",
    "\n",
    "unet_result = unet_model.fit(\n",
    "    images_train, masks_train, \n",
    "    validation_split = 0.2, batch_size = 4, epochs = 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result(idx, og, unet, target, p):\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 3, figsize=(12,12))\n",
    "    axs[0].set_title(\"Original \"+str(idx) )\n",
    "    axs[0].imshow(og)\n",
    "    axs[0].axis('off')\n",
    "    \n",
    "    axs[1].set_title(\"U-Net: p>\"+str(p))\n",
    "    axs[1].imshow(unet)\n",
    "    axs[1].axis('off')\n",
    "    \n",
    "    axs[2].set_title(\"Ground Truth\")\n",
    "    axs[2].imshow(target)\n",
    "    axs[2].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_predict = unet_model.predict(images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1,r2,r3,r4=0.6,0.7,0.8,0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_predict1 = (unet_predict > r1).astype(np.uint8)\n",
    "unet_predict2 = (unet_predict > r2).astype(np.uint8)\n",
    "unet_predict3 = (unet_predict > r3).astype(np.uint8)\n",
    "unet_predict4 = (unet_predict > r4).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_test_idx = random.sample(range(len(unet_predict)), 3)\n",
    "for idx in show_test_idx: \n",
    "    show_result(idx, images_test[idx], unet_predict1[idx], masks_test[idx], r1)\n",
    "    show_result(idx, images_test[idx], unet_predict2[idx], masks_test[idx], r2)\n",
    "    show_result(idx, images_test[idx], unet_predict3[idx], masks_test[idx], r3)\n",
    "    show_result(idx, images_test[idx], unet_predict4[idx], masks_test[idx], r4)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_CV_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
