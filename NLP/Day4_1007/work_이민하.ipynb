{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"_06VZeaydy6d"},"outputs":[],"source":["from Korpora import Korpora\n","import spacy\n","\n","from torch.utils.data import Dataset\n","\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y2JJiJiGdy6e","outputId":"cef141d4-36d7-4f2a-f7de-cc56869cb9ed"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n","    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n","\n","    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n","    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n","    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n","\n","    # Description\n","    Author : e9t@github\n","    Repository : https://github.com/e9t/nsmc\n","    References : www.lucypark.kr/docs/2015-pyconkr/#39\n","\n","    Naver sentiment movie corpus v1.0\n","    This is a movie review dataset in the Korean language.\n","    Reviews were scraped from Naver Movies.\n","\n","    The dataset construction is based on the method noted in\n","    [Large movie review dataset][^1] from Maas et al., 2011.\n","\n","    [^1]: http://ai.stanford.edu/~amaas/data/sentiment/\n","\n","    # License\n","    CC0 1.0 Universal (CC0 1.0) Public Domain Dedication\n","    Details in https://creativecommons.org/publicdomain/zero/1.0/\n","\n","[Korpora] Corpus `nsmc` is already installed at C:\\Users\\KDP-2\\Korpora\\nsmc\\ratings_train.txt\n","[Korpora] Corpus `nsmc` is already installed at C:\\Users\\KDP-2\\Korpora\\nsmc\\ratings_test.txt\n"]}],"source":["nsmc = Korpora.load('nsmc')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IjxRuHJydy6e","outputId":"8fe5073e-f9d9-472c-ee4f-289f1728fa48"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>굳 ㅋ</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>GDNTOPCLASSINTHECLUB</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>지루하지는 않은데 완전 막장임... 돈주고 보기에는....</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text  label\n","0                                                굳 ㅋ      1\n","1                               GDNTOPCLASSINTHECLUB      0\n","2             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n","3                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n","4  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["nsmcDF = pd.DataFrame(nsmc.test)\n","\n","nsmcDF.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HTsIb3nydy6e"},"outputs":[],"source":["class TextDataset(Dataset):\n","    def __init__(self, feature, label):\n","        self.feature = feature\n","        self.label = label\n","        self.n_rows = feature.shape[0]\n","\n","    def __len__(self):\n","        return self.n_rows\n","\n","    def __getitem__(self, index):\n","        return self.feature.iloc[index], self.label.iloc[index]\n",""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p16LF7_Ldy6f"},"outputs":[],"source":["nsmcDS = TextDataset(nsmcDF['text'], nsmcDF['label'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OP_r0irvdy6f","outputId":"e86d18a0-09ca-4215-b342-abf9218478dd"},"outputs":[{"name":"stdout","output_type":"stream","text":["굳 ㅋ 1\n"]}],"source":["for feature, label in nsmcDS:\n","    print(feature, label)\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"waEZ4Uuwdy6f"},"outputs":[],"source":["LANG_MODEL = 'ko_core_news_lg'\n","\n","nlp = spacy.load(LANG_MODEL)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rk_CTcY_dy6f"},"outputs":[],"source":["def generateToken(dataset):\n","    for text, label in dataset:\n","        token_list = []\n","        doc = nlp(text)\n","\n","        for token in doc:\n","            if (not token.is_punct) and (not token.is_stop):\n","                token_list.append(str(token))\n","        yield token_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ExbwQ43ddy6f","outputId":"64e3a1fa-2a17-4883-f82b-77e4364d875c"},"outputs":[{"name":"stdout","output_type":"stream","text":["'굳'\n","'ㅋ'\n","'GDNTOPCLASSINTHECLUB'\n","'뭐야'\n","'평점들은'\n","'나쁘진'\n","'않지만'\n","'10점'\n","'짜리는'\n","'더더욱'\n","'아니잖아'\n","'지루하지는'\n","'않은데'\n","'완전'\n","'막장임'\n","'돈주고'\n","'보기에는'\n","'3D만'\n","'아니었어도'\n","'별'\n","'다섯'\n","'개'\n","'줬을텐데'\n","'왜'\n","'3D로'\n","'나와서'\n","'제'\n","'심기를'\n","'불편하게'\n","'하죠'\n"]}],"source":["token_generator = generateToken(nsmcDS)\n","\n","i = 0\n","for token_list in token_generator:\n","    i += 1\n","    for token in token_list:\n","        print(repr(token))\n","    if i == 5:\n","        break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3nM8HgJDdy6f"},"outputs":[],"source":["token_freqs = {}\n","\n","for token_list in token_generator:\n","    for token in token_list:\n","        if token not in token_freqs:\n","            token_freqs[token] = 1\n","        else:\n","            token_freqs[token] += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G_V-8IOXdy6f","outputId":"e16a8539-5748-4d6a-c3ed-52ae933c76f4"},"outputs":[{"name":"stdout","output_type":"stream","text":["음악이\n","주가\n","된\n","최고의\n","음악영화\n"]}],"source":["i = 0\n","for _ in token_freqs:\n","    print(_)\n","    i += 1\n","    if i == 5:\n","        break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eE9kJHM5dy6g"},"outputs":[],"source":["sorted_tokens = sorted(token_freqs.items(), key = lambda x: x[1], reverse = True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mowtkV18dy6g","outputId":"35d003ff-d222-4ee4-cedd-16277354408a"},"outputs":[{"data":{"text/plain":["('그냥', 1182)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["sorted_tokens[4]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1b9L4m9Kdy6g"},"outputs":[],"source":["PAD_TOKEN, OOV_TOKEN = 'PAD', 'OOV'\n","\n","vocab = {PAD_TOKEN : 0, OOV_TOKEN : 1}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WZSRPuvcdy6g"},"outputs":[],"source":["for index, token in enumerate(sorted_tokens, 2):\n","    vocab[token[0]] = index"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zp1XcObndy6g","outputId":"d7e63851-7067-4520-de25-cf1400de708d"},"outputs":[{"name":"stdout","output_type":"stream","text":["'PAD'\n","'OOV'\n","'영화'\n","'너무'\n","'정말'\n"]}],"source":["i = 0\n","\n","for key in vocab:\n","    print(repr(key))\n","    i += 1\n","    if i == 5:\n","        break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NGPF-_pOdy6g","outputId":"15c42809-2ffb-46e3-99e7-ccfa4f795209"},"outputs":[{"data":{"text/plain":["[[800, 29207, 223, 17, 5625],\n"," [353, 48],\n"," [573, 29208, 29209, 29210, 29211, 7568, 29212],\n"," [233,\n","  29213,\n","  9247,\n","  511,\n","  16912,\n","  29214,\n","  3358,\n","  1662,\n","  29215,\n","  29216,\n","  26,\n","  1533,\n","  29217,\n","  13,\n","  18,\n","  29218],\n"," [11960, 29219, 11961, 426, 16913, 16914, 9248, 143, 254, 11962, 3359]]"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["encoding_data = []\n","\n","for token_list in token_generator:\n","    encoded = []\n","    for token in token_list:\n","        encoded.append(vocab[token])\n","    encoding_data.append(encoded)\n","\n","encoding_data[:5]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cDo0Atrvdy6g","outputId":"78436840-f112-44fd-bb3f-5c048eab00c4"},"outputs":[{"data":{"text/plain":["38"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["data_length = [len(data) for data in encoding_data]\n","\n","data_length\n","MAX_LENGTH = max(data_length)\n","\n","MAX_LENGTH"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JEOQ8SD0dy6g"},"outputs":[],"source":["for index, data in enumerate(encoding_data):\n","    current_length = len(data)\n","    if current_length < MAX_LENGTH:\n","        encoding_data[index] = data + ([0] * (MAX_LENGTH - current_length))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AMLPiYsrdy6g","outputId":"0845ea32-4c2e-4331-fdf8-b885e0a4b004"},"outputs":[{"name":"stdout","output_type":"stream","text":["38 [800, 29207, 223, 17, 5625, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","38 [353, 48, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","38 [573, 29208, 29209, 29210, 29211, 7568, 29212, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","38 [233, 29213, 9247, 511, 16912, 29214, 3358, 1662, 29215, 29216, 26, 1533, 29217, 13, 18, 29218, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","38 [11960, 29219, 11961, 426, 16913, 16914, 9248, 143, 254, 11962, 3359, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"]}],"source":["for data in encoding_data[:5]:\n","    print(len(data), data)"]}],"metadata":{"kernelspec":{"display_name":"TEXT_018_230_38","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.19"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}