{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 사용자 정의 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "- 함수 기능 : 모델 학습 진행 함수  \n",
    "- 함수 이름 : training   \n",
    "- 매개 변수 : 함수 구동 시 필요한 재료 >> 학습을 위한 재료   \n",
    "            * 모델 인스턴스   \n",
    "            * 학습 데이터셋 : feature, target(label) (학습전 Tensor화)   \n",
    "            * 손실함수 인스턴스    \n",
    "            * 최적화 인스턴스    \n",
    "            * 학습 횟수 : 에포크(EPOCH)   \n",
    "            * 배치 크기 : BATCH_SIZE    \n",
    "            * 배치 개수 : BATCH_CNT    \n",
    "            * 검증용 데이터셋 : feature, target (학습전 Tensor화)    \n",
    "- 함수 결과 : 학습 시 에포크당 손실값과 성능지표값, 검증의 손실값과 성능지표값     \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "- 함수 기능 : 에포크 단위 모델 학습 진행 함수\n",
    "- 함수 이름 : EpochTraining\n",
    "- 매개 변수 : 함수 구동 시 필요한 재료 >> 학습을 위한 재료  \n",
    "            * 모델 인스턴스   \n",
    "            * 학습 데이터셋 : feature, target(label) (학습전 Tensor화)   \n",
    "            * 손실함수 인스턴스   \n",
    "            * 최적화 인스턴스    \n",
    "            * 배치크기 : BATCH_SIZE    \n",
    "            * 배치 개수 : BATCH_CNT     \n",
    "- 함수 결과 : 손실값과 성능지표값   >> tuple로 담아서\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 로딩\n",
    "\n",
    "import torch                        # 텐서 및 수치 계산 함수 관련 모듈\n",
    "import torch.nn as nn               # 인공신경망 관련 모듈\n",
    "import torch.nn.functional as F     # 손실, 거리 등 함수 관련 모듈\n",
    "import torch.optim as optimizer     # 최적화 기법 관련 모듈\n",
    "import pandas as pd                 # 데이터 파일 분석 관련 모듈\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchmetrics.regression import R2Score  # 성능 지표 관련 모듈 \n",
    "from torchmetrics.classification import F1Score # 성능 지표 관련 모듈\n",
    "from torchinfo import summary       # 모델 정보 관련 모듈\n",
    "\n",
    "# 텐서 저장 및 실행 위치 설정\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 에포크 당 학습 진행 후 손실값과 성능지표값 반환 함수 >>> 여긴 뷴류 회귀 받는 함수 만들기\n",
    "def EpochTraining(model, feature, target, lossFunc, optimizer, batch_cnt, batch_size = 32): # 디폴트값으로 주고싶은 것은 뒤로 보내고 값을 지정해주면 됩니다.\n",
    "    # 에포크에서 배치크기만큼 데이터셋 추출 후 학습 진행\n",
    "    loss_total, score_total = 0, 0\n",
    "    for batch in range(batch_cnt):\n",
    "        # 배치크기만큼 데이터셋 추출 및 덴서화\n",
    "        start = batch * batch_size # 예) batch_size=32 >> 0,32,64,...\n",
    "        end = start + batch_size # 예) batch_size=32 >> 32,64,96...\n",
    "\n",
    "        X_train = torch.FloatTensor(feature[start:end].values).to(DEVICE)\n",
    "        y_train = torch.FloatTensor(target[start:end].values).to(DEVICE)\n",
    "\n",
    "        # 학습 진행\n",
    "        pre_y = model(X_train)\n",
    "\n",
    "        # 손실 계산 >> 변경\n",
    "        loss = lossFunc(pre_y, y_train)\n",
    "        loss_total += loss\n",
    "\n",
    "        # 점수 추출   >> 변경                                #()까지 해야 인스턴스 생성\n",
    "        score = F1Score()(pre_y, y_train) if is_class else R2Score()(pre_y, y_train) # 여기서 분류인지 회귀인지 분류\n",
    "        score_total += score\n",
    "\n",
    "        # 최적화 \n",
    "        # - 분류 >>\n",
    "        # - 회귀 >> 정답에 가까운 가중치(W)와 절편(b)을 찾음\n",
    "            # 지금은 : W, b를 업데이트\n",
    "        optimizer.zero_grad()\n",
    "        loss.bachkward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # 에포크당 손실값과 성능지표값 판정\n",
    "    # 테스트 및 검증 함수 사용 >> 검증하는이유 >> 과대, 과소적합인지 아닌지, 학습이 멈출지 말지(오래하면 비례하다 떨어지는경우가 있기에 그시점을 알고 끊어 주기위해) \n",
    "    return loss_total/batch_cnt, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 에포크 당 학습 진행 후 손실값과 성능지표값 반환 함수\n",
    "def EpochTraining(model, feature, target, lossFunc, optimizer, batch_cnt, batch_size = 32, is_class=True): # 디폴트값으로 주고싶은 것은 뒤로 보내고 값을 지정해주면 됩니다.\n",
    "    # 에포크에서 배치크기만큼 데이터셋 추출 후 학습 진행\n",
    "    loss_total, score_total = 0, 0\n",
    "    for batch in range(batch_cnt):\n",
    "        # 배치크기만큼 데이터셋 추출 및 덴서화\n",
    "        start = batch * batch_size # 예) batch_size=32 >> 0,32,64,...\n",
    "        end = start + batch_size # 예) batch_size=32 >> 32,64,96...\n",
    "\n",
    "        X_train = torch.FloatTensor(feature[start:end].values).to(DEVICE)\n",
    "        y_train = torch.FloatTensor(target[start:end].values).to(DEVICE)\n",
    "\n",
    "        # 학습 진행\n",
    "        pre_y = model(X_train).to(DEVICE)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = lossFunc(pre_y, y_train)\n",
    "        loss_total += loss\n",
    "\n",
    "        # 점수 추출                                         #()까지 해야 인스턴스 생성\n",
    "        score = F1Score()(pre_y, y_train) if is_class else R2Score()(pre_y, y_train) # 여기서 분류인지 회귀인지 분류\n",
    "        score_total += score\n",
    "\n",
    "        # 최적화 \n",
    "        # - 분류 >> ?>????\n",
    "        # - 회귀 >> 정답에 가까운 가중치(W)와 절편(b)을 찾음\n",
    "            # 지금은 : W, b를 업데이트\n",
    "        optimizer.zero_grad()\n",
    "        loss.bachkward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # 에포크당 손실값과 성능지표값 판정\n",
    "    # 테스트 및 검증 함수 사용 >> 검증하는이유 >> 과대, 과소적합인지 아닌지, 학습이 멈출지 말지(오래하면 비례하다 떨어지는경우가 있기에 그시점을 알고 끊어 주기위해) \n",
    "    return loss_total/batch_cnt, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 검증 및 테스트 진행 후 손실값과 성능지표값 반환 함수\n",
    "def testing(model, feature, target, lossFunc, scoreFunc):\n",
    "    # 최적화 기능 비활성화 후 데이터셋 추출 후 학습 진행\n",
    "    loss_total, score_total = 0, 0\n",
    "    with  torch.no_grad():\n",
    "        # 데이터셋 덴서ghk\n",
    "        featureTS = torch.FloatTensor(feature.values).to(DEVICE)\n",
    "        targetTS = torch.FloatTensor(target.values).to(DEVICE)\n",
    "\n",
    "        # 학습 진행\n",
    "        pre_y = model(featureTS).to(DEVICE)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = lossFunc(pre_y, targetTS)\n",
    "        loss_total += loss\n",
    "\n",
    "        # 점수 추출                       \n",
    "        score = scoreFunc(pre_y, targetTS)\n",
    "    \n",
    "    # 손실값과 성능지표값 변환\n",
    "    return loss, score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 학습 진행\n",
    "EPOCHS =10\n",
    "TV_LOSS = {'TRAIN':[], 'VAL':[]}\n",
    "TV_SCORE = {'TRAIN':[], 'VAL':[]}\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    # 학습 진행\n",
    "    train_loss, train_score = EpochTraining()\n",
    "    \n",
    "    # 검증 진행\n",
    "    val_loss, val_score = testing()\n",
    "\n",
    "    # 에포크당 학습 및 검증 결과 저장\n",
    "    TV_LOSS['TRAIN'].append(train_loss)\n",
    "    TV_SCORE['TRAIN'].append(train_score)\n",
    "    \n",
    "    TV_LOSS['Val'].append(val_loss)\n",
    "    TV_SCORE['Val'].append(val_score)\n",
    "\n",
    "    # 에포크당 학습 및 검증 결과 출력\n",
    "    print(f'[{epoch}/{EPOCHS}]\\n -[Train] LOSS : {train_loss}  SCORE : {train_score}')\n",
    "    print(f'[{epoch}/{EPOCHS}]\\n -[Val] LOSS : {val_loss}  SCORE : {val_score}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
