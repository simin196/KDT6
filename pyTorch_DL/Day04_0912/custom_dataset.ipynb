{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 사용자 정의 데이터셋\n",
    " - Pytorch에서 딥러닝 시 대량의 데이터 사용에 따른 부하(H/W, S/W) 및 많은 시간 소요에 대한 해결책으로 제시\n",
    " - 대량 데이터셋 전용 처리 모듈 제공\n",
    " - Dataset과 DataLoader\n",
    "    * Dataset => 데이터셋 전터리, 텐서화 등의 작업 진행\n",
    "    * DataLoader => Dataset 인스턴스를 사용해서 배치크기 만큼 데이터를 추출함\n",
    "      +  Dataset이 있어야 dataLoader을 할수있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] 모듈로딩 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 로딩\n",
    "\n",
    "import torch                        # 텐서 및 수치 계산 함수 관련 모듈\n",
    "import torch.nn as nn               # 인공신경망 관련 모듈\n",
    "import torch.nn.functional as F     # 손실, 거리 등 함수 관련 모듈\n",
    "import torch.optim as optimizer     # 최적화 기법 관련 모듈\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd                 # 데이터 파일 분석 관련 모듈\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchmetrics.regression import R2Score  # 성능 지표 관련 모듈 \n",
    "from torchmetrics.classification import F1Score # 성능 지표 관련 모듈\n",
    "from torchinfo import summary       # 모델 정보 관련 모듈\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터\n",
    "DATA_FILE = '../data/iris.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width variety\n",
       "0           5.1          3.5           1.4          0.2  Setosa\n",
       "1           4.9          3.0           1.4          0.2  Setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CSV => DF\n",
    "irisDF = pd.read_csv(DATA_FILE)\n",
    "irisDF.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟 컬럼 수치화 ==>  LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(irisDF['variety'])\n",
    "irisDF['variety'] = encoder.transform(irisDF['variety'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] 사용자 정의 데이터셋 클래스 생성\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------\n",
    "# 클래스 목적 : 학습용 데이터셋 텐서화 및 전처리\n",
    "# 클래스 이름 : CustomDataSet\n",
    "# 부모 클래스 : torch.utils.data.dataset\n",
    "# 매개 변수 : featureDF, targetDF\n",
    "# >> 밖에서 전처리한걸 들고왔음\n",
    "#-------------------------------------------------------\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    # 데이터 로딩 및 전처리 진행과 인스턴스 생성 메서드\n",
    "    def __init__(self,featureDF, targetDF) :\n",
    "        super().__init__()\n",
    "        self.featureDF = featureDF \n",
    "        self.targetDF = targetDF\n",
    "        self.n_rows = featureDF.shape[0]\n",
    "        self.n_features = featureDF.shape[1]\n",
    "\n",
    "    # 데이터의 개수 반환 메서드\n",
    "    def __len__(self):\n",
    "        return self.n_rows\n",
    "\n",
    "    # 특정 index의 데이터와 타겟 반환 메서드 => Tensor 변환!!\n",
    "    def __getitem__(self, idx):\n",
    "        featureTS = torch.FloatTensor(self.featureDF.iloc[idx].values)\n",
    "        targetTS = torch.FloatTensor(self.targetDF.iloc[idx].values)\n",
    "        return featureTS, targetTS\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------\n",
    "# 클래스 목적 : 파일 확장자별 데이터프레임 변환 기능\n",
    "# 클래스 이름 : convertDataFrame\n",
    "# 매개 변수 : data_path\n",
    "# 함수 결과 : DataFrame\n",
    "#-------------------------------------------------------\n",
    "\n",
    "def convertDataFrame(data_path, exit_header=0):\n",
    "    ext = data_path.rsplit('.')[-1]\n",
    "    if ext == 'csv':\n",
    "        return pd.read_csv(data_path, header = exit_header)\n",
    "    elif ext == 'json':\n",
    "        return pd.read_json(data_path, header = exit_header)\n",
    "    elif ext in [ 'xlsx', 'xls']:\n",
    "        return pd.read_excel(data_path, header = exit_header)\n",
    "    else:\n",
    "        return pd.read_table(data_path, header = exit_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------\n",
    "# 클래스기능 : 파일기반 데이터셋\n",
    "# 클래스 명 : FileDataset\n",
    "# 매개 변수 : data_path 파일 경로\n",
    "# 부모 클래스 : utils.data.Dataset\n",
    "# >> 파일을 받아서 위에서 확장자들 별로 달라지기에 1차적으로 데이터프레임을 빼오고\n",
    "# 2. 데이터 프레임을 빼오고 이제 피쳐 라벨 분리하고,  지금 위아래 한세트\n",
    "#-------------------------------------------------------  \n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    # 데이터 로딩 및 전처리 진행과 인스턴스 생성 메서드\n",
    "    def __init__(self,data_path) :\n",
    "        super().__init__()\n",
    "        \n",
    "        # 데이터 파일 ==> DF로 변환 \n",
    "        dataDF = convertDataFrame(data_path)\n",
    "        \n",
    "        # DF ==> 피쳐와 라벨 추출\n",
    "        self.featuresDF = dataDF[dataDF.columns[:-1]]\n",
    "        self.targetDF = dataDF[dataDF.columns[-1:]]\n",
    "\n",
    "        self.n_features = self.featuresDF.shape[1]\n",
    "        self.n_rows = self.featuresDF.shape[0]\n",
    "\n",
    "\n",
    "    # 데이터의 개수 반환 메서드\n",
    "    def __len__(self):\n",
    "        return self.n_rows\n",
    "\n",
    "    # 특정 index의 데이터와 타겟 반환 메서드 => Tensor 변환!!\n",
    "    def __getitem__(self, idx):\n",
    "        featureTS = torch.FloatTensor(self.featureDF.iloc[idx].values)\n",
    "        targetTS = torch.FloatTensor(self.targetDF.iloc[idx].values)\n",
    "        return featureTS, targetTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] 데이터셋 인스턴스 생성 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featureDF => (150, 4) , targetDF => (150, 1)\n"
     ]
    }
   ],
   "source": [
    "# 피쳐와 타게 추출\n",
    "featureDF, targetDF = irisDF[irisDF.columns[:-1]], irisDF[irisDF.columns[-1:]]  # irisDF[[irisDF.columns[-1]]]도 가능\n",
    "print(f'featureDF => {featureDF.shape} , targetDF => {targetDF.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris 데이터셋 인스턴스 생성\n",
    "irisDS = CustomDataset(featureDF, targetDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     sepal.length  sepal.width  petal.length  petal.width\n",
       " 0             5.1          3.5           1.4          0.2\n",
       " 1             4.9          3.0           1.4          0.2\n",
       " 2             4.7          3.2           1.3          0.2\n",
       " 3             4.6          3.1           1.5          0.2\n",
       " 4             5.0          3.6           1.4          0.2\n",
       " ..            ...          ...           ...          ...\n",
       " 145           6.7          3.0           5.2          2.3\n",
       " 146           6.3          2.5           5.0          1.9\n",
       " 147           6.5          3.0           5.2          2.0\n",
       " 148           6.2          3.4           5.4          2.3\n",
       " 149           5.9          3.0           5.1          1.8\n",
       " \n",
       " [150 rows x 4 columns],\n",
       " 4,\n",
       " 150)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iris 데이터셋 속성 >> [상자] 모양\n",
    "irisDS.featureDF , irisDS.n_features, irisDS.n_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([5.1000, 3.5000, 1.4000, 0.2000]), tensor([0.]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iris 데이터셋 메서드\n",
    "irisDS[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4] DataLoader 인스턴스 생성 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 필요한 것 : Dataset 인스턴스, Batch_size\n",
    "irisDL = DataLoader(irisDS, batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4]) torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "for datTS, targetTS in irisDL:\n",
    "    print(datTS.shape, targetTS.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
