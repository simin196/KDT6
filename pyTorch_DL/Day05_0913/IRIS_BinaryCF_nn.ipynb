{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DNN 기반 이진분류 모델 구현\n",
    "- 데이터셋 : iris.csv\n",
    "- 피쳐/라벨 : 4개 sepal.length, sepal.width, petal.length, petal.width\n",
    "- 타겟/라벨 : 1개 Setosa와 나머지 (이진 분류이기에 클래스는 2개)\n",
    "- 학습 방법 : 지도 학습 > 분류 > 이진분류\n",
    "- 학습 알고리즘 : 인공신경망(ANN) =>> 심층신경막(입력층, 은닉층, 출력층 있는거) MLP , DNN : 은닉층이 많은 구성\n",
    "- 프레임 워크 : Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] 모듈 로딩 및 데이터 준비 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 로딩\n",
    "# 1. 모델관련\n",
    "import torch                     # 텐서 및 수치 계산 함수 관련 모듈\n",
    "import torch.nn as nn            # 인공신경망 관련 모듈\n",
    "import torch.nn.functional as F  # 손실, 거리 등 함수 관련 모듈\n",
    "\n",
    "# 2. 데이터 셋 관련                    \n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# 3. 최적화에 관련\n",
    "import torch.optim as optim      # 최적화 기법 관련 모듈\n",
    "\n",
    "# 4. 모델 평가\n",
    "from torchmetrics.classification import F1Score, BinaryF1Score, BinaryConfusionMatrix\n",
    "\n",
    "# 5. 모델의 구조를 보는 모듈\n",
    "from torchinfo import summary    # 모델 정보 관련 모듈\n",
    "\n",
    "# 6. Data 관련\n",
    "import pandas as pd                 # 데이터 파일 분석 관련 모듈\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytroch v.2.4.1\n",
      "Pandas v.2.0.3\n"
     ]
    }
   ],
   "source": [
    "# 활용 패키지 버전 체크 ==> 사용자 정의 함수로 구현하세요~~\n",
    "print(f'Pytroch v.{torch.__version__}')\n",
    "print(f'Pandas v.{pd.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width variety\n",
       "0           5.1          3.5           1.4          0.2  Setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 로딩\n",
    "DATA_file ='../data/iris.csv'\n",
    "\n",
    "# CSV >> DF\n",
    "irisDF = pd.read_csv(DATA_file)\n",
    "\n",
    "# 확인\n",
    "irisDF.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Setosa', 'Versicolor', 'Virginica'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 타겟 변경 >> 정수화, 클래스 3개 >> 2개로 변경\n",
    "irisDF['variety'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 0]),\n",
       "    sepal.length  sepal.width  petal.length  petal.width  variety\n",
       " 0           5.1          3.5           1.4          0.2        1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 클래스 3개 >> 2개로 변경\n",
    "irisDF['variety'] = (irisDF['variety'] == 'Setosa')\n",
    "irisDF['variety'] = irisDF['variety'].astype('int')\n",
    "irisDF['variety'].unique() , irisDF.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 타겟 정수화\n",
    "# label = dict(zip(irisDF['variety'].unique().tolist(), range(3)))\n",
    "# print(f'label => {label}')\n",
    "# irisDF['variety'] = irisDF['variety'].replace(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] 모델 클래스 설계 및 정의 <hr>\n",
    "- 클래스 목적 : iris 데이터를 학습 및 추론 목적\n",
    "- 클래스 이름 : IrisBCFModel\n",
    "- 부모 클래스 : nn.Module\n",
    "- 매개 변수 : 층별 입출력 개수 고정하기 때문에 필요 없음\n",
    "- 속성 필드 : \n",
    "- 기능 역할(필수 메서드) : _ _init_ _() - 모델 구조 설정, forward() - 순방향 학습 <== 오버라이딩(overriding) >> 상속받을 때만 가능\n",
    "- 클래스 구조\n",
    "    * 입력층 - 입력  4개 (피쳐 개수) >  출력 10개 (퍼셉트론 / 뉴런 10개 존재)\n",
    "    * 은닉층 - 입력 10개            >  출력  5개 (퍼셉트론 / 뉴런 5개 존재)\n",
    "    * 출력층 - 입력 5개             >  출력  1개 (퍼셉트론 / 뉴런 1개 존재, 2진분류)\n",
    "\n",
    "- 활성화함수\n",
    "    * 클래스 형태 ==> nn.MESLose, nn.ReLU ==> _ _init_ _() 메서드\n",
    "    * 함수 형태 ==> torch.nn.functional 아래에 ==> forward() 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisBCMModel(nn.Module):\n",
    "\n",
    "    # 모델 구조 구성 및 인스턴스 생성 메서드\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_layer = nn.Linear(4,10)\n",
    "        self.hd_layer = nn.Linear(10,5)\n",
    "        self.out_layer = nn.Linear(5,1)\n",
    "\n",
    "    # 순방향 학습 진행 메서드\n",
    "    def forward(self, input_data):\n",
    "\n",
    "        # 입력층 \n",
    "        y = self.in_layer(input_data)   \n",
    "        y = F.relu(y)                   # relu => y값의 범위 : 0 <= y\n",
    "\n",
    "        # 은닉층 : 10개의 숫자 값(y >= 0)\n",
    "        y=self.hd_layer(y)\n",
    "        y = F.relu(y)\n",
    "\n",
    "        # 출력층 : 5개의 숫자 값(y >= 0) >> 2진분류\n",
    "        return F.sigmoid(self.out_layer(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IrisBCMModel(\n",
      "  (in_layer): Linear(in_features=4, out_features=10, bias=True)\n",
      "  (hd_layer): Linear(in_features=10, out_features=5, bias=True)\n",
      "  (out_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 모델 인스턴스 생성[확인 용도]\n",
    "model = IrisBCMModel()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "IrisBCMModel                             [17, 1]                   --\n",
       "├─Linear: 1-1                            [17, 10]                  50\n",
       "├─Linear: 1-2                            [17, 5]                   55\n",
       "├─Linear: 1-3                            [17, 1]                   6\n",
       "==========================================================================================\n",
       "Total params: 111\n",
       "Trainable params: 111\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 모델 사용 메로리 정보 확인\n",
    "summary(model, input_size=(17,4)) # 데이터양, 피쳐개수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] 데이터셋 클래스 설계 및 정의 <hr>\n",
    "- 데이터셋 : iris.csv\n",
    "- 피쳐 개수 : 4개\n",
    "- 타겟 개수 : 1개\n",
    "- 클래스 이름 : IrisDataset\n",
    "- 부모클래스 : utils.data.Dataset\n",
    "- 속성_필드 : featuresDF, targetDF, n_rows, n_features\n",
    "- 필수메서드\n",
    "    * __init__(self) : 데이터셋 저장 및 전처리, 개발자가 필요한 속성 설정\n",
    "    * __len__(self) : 데이터의 개수 반환\n",
    "    * __getitme__(self, index) : 특정 인덱스의 피쳐와 타겟 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisDataset(Dataset):\n",
    "    def __init__(self, featureDF, targetDF):\n",
    "        self.featureDF = featureDF\n",
    "        self.targetDF = targetDF\n",
    "        self.n_rows = featureDF.shape[0] # >> 새로 속성 추가, 데이터 수 확인\n",
    "        self.n_features = featureDF.shape[1] # >> 새로 속성 추가, 피쳐 개수 확인\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_rows\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "    \n",
    "        # 텐서화\n",
    "        featureTS = torch.FloatTensor(self.featureDF.iloc[index].values) # values하는 이유 >> array를 하기위해\n",
    "        targetTS = torch.FloatTensor(self.targetDF.iloc[index].values)\n",
    "\n",
    "        # 피쳐와 타겟 반환\n",
    "        return featureTS, targetTS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4]) torch.Size([1, 1]) tensor([[5.1000, 3.5000, 1.4000, 0.2000]]) tensor([[1.]])\n"
     ]
    }
   ],
   "source": [
    "## [테스트] 데이터셋 인스턴스 생성 \n",
    "\n",
    "# DF에서 피쳐와 타겟 추출\n",
    "featureDF = irisDF[irisDF.columns[:-1]] # 2D (150,4)\n",
    "targetDF = irisDF[irisDF.columns[-1:]]  # 2D (150,1)\n",
    "\n",
    "# 커스텀데이터셋 인스턴스 생성\n",
    "irisDS = IrisDataset(featureDF, targetDF)\n",
    "\n",
    "# 데이터 로더 인스턴스 생성\n",
    "irisDL = DataLoader(irisDS)\n",
    "for feature, label in irisDL:\n",
    "    print(feature.shape, label.shape, feature, label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4] 학습 준비 <hr>\n",
    "- 학습 횟수 : EPOCH     << 처음 ~ 끝까지 공부하는 단위\n",
    "- 배치 크기 : BATCH_SIZE    << 한번에 학습할 데이터셋 양\n",
    "- 위치 지정 : DEVICE    << 텐서 저장 및 실행 위치(GPU/CPU)\n",
    "- 학습률 : LR   << 가중치와 절편 업데이트 시 경사하강법으로 업데이트 간격 설정, 0.001 ~ 0.1 사이를 많이 줌(값이 작을수록 촘촘하게 이동) >> 하이퍼 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 학습 진행 관련 설정\n",
    "EPOCH = 1000\n",
    "BATCH_SIZE = 10\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 인스턴스/객체 : 모델, 데이터셋, 최적화 (, 손실함수 , 성능 지표)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 인스턴스\n",
    "model = IrisBCMModel().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 4) (38, 4) (28, 4)\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.frame.DataFrame'> <class 'pandas.core.frame.DataFrame'>\n",
      "(84, 1) (38, 1) (28, 1)\n",
      "variety\n",
      "0          56\n",
      "1          28\n",
      "Name: count, dtype: int64 variety\n",
      "0          25\n",
      "1          13\n",
      "Name: count, dtype: int64 variety\n",
      "0          19\n",
      "1           9\n",
      "Name: count, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.frame.DataFrame'> <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "## DS와 DL 인스턴스\n",
    "# 학습용, 검증용, 테스트용 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(featureDF, targetDF, random_state=1, stratify=targetDF)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=1, stratify=y_train)\n",
    "\n",
    "print(f'{X_train.shape} {X_test.shape} {X_val.shape}')\n",
    "print(f'{type(X_train)} {type(X_test)} {type(X_val)}')\n",
    "print(f'{y_train.shape} {y_test.shape} {y_val.shape}')\n",
    "print(f'{y_train.value_counts()} {y_test.value_counts()} {y_val.value_counts()}')\n",
    "print(f'{type(y_train)} {type(y_test)} {type(y_val)}')\n",
    "\n",
    "# 테이터 확인\n",
    "trainDS = IrisDataset(X_train, y_train)\n",
    "testDS = IrisDataset(X_test, y_test)\n",
    "valDS = IrisDataset(X_val, y_val)\n",
    "\n",
    "# 학습용 데이터로더 인스턴스\n",
    "trainDL = DataLoader(trainDS, batch_size=BATCH_SIZE) ## >> 'drop_last = True' 하면 나머지는 버림, 기본값은 False\n",
    "                                                      # >> 기본값은 나머지가 생기면 앞에 나열되있던 데이터를 필요한만큼 끌고와 대입입"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 최적화, 손실함수 인스턴스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적화 인스턴스 => W,b텐서 즉, model.parameters() 전달 >> W,b 업데이트 시키는이유 >>> 오차를 줄여 최적의 모델을 찾기위해  \n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# 소실함수 인스턴스 => 분류 >> 이진 분류 BinaryCrossEntropyLoss => BCELoss\n",
    "#                             예측값은 확률값으로 전달 ==> sigmoid() AF처리 후 전달\n",
    "crossLoss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[5] 학습 진행 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.4, 9, 84)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math as m \n",
    "\n",
    "trainDS.n_rows/BATCH_SIZE, m.ceil(trainDS.n_rows/BATCH_SIZE) , trainDS.featureDF.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 9)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataLoader로 8.4에서 9로 바꾼다. > 나머지가 남으면 부족한 만큼 앞에 있는 데이터를 가져다가 쓴다\n",
    "len(trainDL), trainDL.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1000]\n",
      "- [TRAIN] LOSS : 0.8356667955716451 SCORE : 0.49842751026153564\n",
      "- [VALID] LOSS : 0.8231714963912964 SCORE : 0.6666666865348816\n",
      "[2/1000]\n",
      "- [TRAIN] LOSS : 0.8036811484230889 SCORE : 0.49842751026153564\n",
      "- [VALID] LOSS : 0.7937769889831543 SCORE : 0.6666666865348816\n",
      "[3/1000]\n",
      "- [TRAIN] LOSS : 0.7778173486391703 SCORE : 0.49842751026153564\n",
      "- [VALID] LOSS : 0.7683992981910706 SCORE : 0.6666666865348816\n",
      "[4/1000]\n",
      "- [TRAIN] LOSS : 0.7554430696699355 SCORE : 0.4455174207687378\n",
      "- [VALID] LOSS : 0.7455970644950867 SCORE : 0.6666666865348816\n",
      "[5/1000]\n",
      "- [TRAIN] LOSS : 0.7352108160654703 SCORE : 0.286868691444397\n",
      "- [VALID] LOSS : 0.7249585390090942 SCORE : 0.4000000059604645\n",
      "[6/1000]\n",
      "- [TRAIN] LOSS : 0.7167912324269613 SCORE : 0.24713805317878723\n",
      "- [VALID] LOSS : 0.7062982320785522 SCORE : 0.4000000059604645\n",
      "[7/1000]\n",
      "- [TRAIN] LOSS : 0.6997337407535977 SCORE : 0.2700176239013672\n",
      "- [VALID] LOSS : 0.6889067888259888 SCORE : 0.5\n",
      "[8/1000]\n",
      "- [TRAIN] LOSS : 0.6835478213098314 SCORE : 0.3936507999897003\n",
      "- [VALID] LOSS : 0.6723946928977966 SCORE : 0.6666666865348816\n",
      "[9/1000]\n",
      "- [TRAIN] LOSS : 0.6680260499318441 SCORE : 0.6439153552055359\n",
      "- [VALID] LOSS : 0.6569195985794067 SCORE : 1.0\n",
      "[10/1000]\n",
      "- [TRAIN] LOSS : 0.6538809670342339 SCORE : 0.714550256729126\n",
      "- [VALID] LOSS : 0.6435325741767883 SCORE : 1.0\n",
      "[11/1000]\n",
      "- [TRAIN] LOSS : 0.641697022649977 SCORE : 0.7756614089012146\n",
      "- [VALID] LOSS : 0.6309664845466614 SCORE : 1.0\n",
      "[12/1000]\n",
      "- [TRAIN] LOSS : 0.6302755276362101 SCORE : 0.9238095879554749\n",
      "- [VALID] LOSS : 0.6188850402832031 SCORE : 1.0\n",
      "[13/1000]\n",
      "- [TRAIN] LOSS : 0.6190198858579 SCORE : 0.9460318088531494\n",
      "- [VALID] LOSS : 0.6068916916847229 SCORE : 1.0\n",
      "[14/1000]\n",
      "- [TRAIN] LOSS : 0.6075600783030192 SCORE : 0.9682539701461792\n",
      "- [VALID] LOSS : 0.5947823524475098 SCORE : 1.0\n",
      "[15/1000]\n",
      "- [TRAIN] LOSS : 0.5958053270975748 SCORE : 0.9682539701461792\n",
      "- [VALID] LOSS : 0.5823127627372742 SCORE : 1.0\n",
      "[16/1000]\n",
      "- [TRAIN] LOSS : 0.5835920174916586 SCORE : 0.9841270446777344\n",
      "- [VALID] LOSS : 0.5692704916000366 SCORE : 1.0\n",
      "[17/1000]\n",
      "- [TRAIN] LOSS : 0.5708615846104093 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.5556768178939819 SCORE : 1.0\n",
      "[18/1000]\n",
      "- [TRAIN] LOSS : 0.5575059718555875 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.5414305925369263 SCORE : 1.0\n",
      "[19/1000]\n",
      "- [TRAIN] LOSS : 0.543440494272444 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.5264067053794861 SCORE : 1.0\n",
      "[20/1000]\n",
      "- [TRAIN] LOSS : 0.5285990370644463 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.5105541944503784 SCORE : 1.0\n",
      "[21/1000]\n",
      "- [TRAIN] LOSS : 0.5129258036613464 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.4937501847743988 SCORE : 1.0\n",
      "[22/1000]\n",
      "- [TRAIN] LOSS : 0.49664538436465794 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.47618064284324646 SCORE : 1.0\n",
      "[23/1000]\n",
      "- [TRAIN] LOSS : 0.47986633247799343 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.4581964910030365 SCORE : 1.0\n",
      "[24/1000]\n",
      "- [TRAIN] LOSS : 0.46254371603329975 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.4398145377635956 SCORE : 1.0\n",
      "[25/1000]\n",
      "- [TRAIN] LOSS : 0.44471366206804913 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.4209909737110138 SCORE : 1.0\n",
      "[26/1000]\n",
      "- [TRAIN] LOSS : 0.4264719585577647 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.40183088183403015 SCORE : 1.0\n",
      "[27/1000]\n",
      "- [TRAIN] LOSS : 0.4079387949572669 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.3825030028820038 SCORE : 1.0\n",
      "[28/1000]\n",
      "- [TRAIN] LOSS : 0.3891578283574846 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.362993448972702 SCORE : 1.0\n",
      "[29/1000]\n",
      "- [TRAIN] LOSS : 0.37019305096732247 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.3435295522212982 SCORE : 1.0\n",
      "[30/1000]\n",
      "- [TRAIN] LOSS : 0.35112642248471576 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.3242030143737793 SCORE : 1.0\n",
      "[31/1000]\n",
      "- [TRAIN] LOSS : 0.3321925931506687 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.3051213324069977 SCORE : 1.0\n",
      "[32/1000]\n",
      "- [TRAIN] LOSS : 0.31361934211519027 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.2864862382411957 SCORE : 1.0\n",
      "[33/1000]\n",
      "- [TRAIN] LOSS : 0.29553541872236466 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.26892104744911194 SCORE : 1.0\n",
      "[34/1000]\n",
      "- [TRAIN] LOSS : 0.27827059229214984 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.2519955039024353 SCORE : 1.0\n",
      "[35/1000]\n",
      "- [TRAIN] LOSS : 0.26152651343080735 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.23569133877754211 SCORE : 1.0\n",
      "[36/1000]\n",
      "- [TRAIN] LOSS : 0.24545740915669334 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.22010669112205505 SCORE : 1.0\n",
      "[37/1000]\n",
      "- [TRAIN] LOSS : 0.2301116089026133 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.20525838434696198 SCORE : 1.0\n",
      "[38/1000]\n",
      "- [TRAIN] LOSS : 0.21548630628320906 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.19118031859397888 SCORE : 1.0\n",
      "[39/1000]\n",
      "- [TRAIN] LOSS : 0.20158930950694615 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.17793776094913483 SCORE : 1.0\n",
      "[40/1000]\n",
      "- [TRAIN] LOSS : 0.18846898939874437 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.16553786396980286 SCORE : 1.0\n",
      "[41/1000]\n",
      "- [TRAIN] LOSS : 0.17615100079112583 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.15395091474056244 SCORE : 1.0\n",
      "[42/1000]\n",
      "- [TRAIN] LOSS : 0.16461850702762604 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.14315542578697205 SCORE : 1.0\n",
      "[43/1000]\n",
      "- [TRAIN] LOSS : 0.15384572413232592 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.13312862813472748 SCORE : 1.0\n",
      "[44/1000]\n",
      "- [TRAIN] LOSS : 0.1438049938943651 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.12384630739688873 SCORE : 1.0\n",
      "[45/1000]\n",
      "- [TRAIN] LOSS : 0.1344757518834538 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.11526603251695633 SCORE : 1.0\n",
      "[46/1000]\n",
      "- [TRAIN] LOSS : 0.12581750750541687 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.10734663903713226 SCORE : 1.0\n",
      "[47/1000]\n",
      "- [TRAIN] LOSS : 0.11779131243626277 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.10005134344100952 SCORE : 1.0\n",
      "[48/1000]\n",
      "- [TRAIN] LOSS : 0.11036164147986306 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.09332450479269028 SCORE : 1.0\n",
      "[49/1000]\n",
      "- [TRAIN] LOSS : 0.10348633925120036 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.08713486045598984 SCORE : 1.0\n",
      "[50/1000]\n",
      "- [TRAIN] LOSS : 0.09712204088767369 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.08145295083522797 SCORE : 1.0\n",
      "[51/1000]\n",
      "- [TRAIN] LOSS : 0.09122652146551344 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.07623448222875595 SCORE : 1.0\n",
      "[52/1000]\n",
      "- [TRAIN] LOSS : 0.08578941308789784 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0714312195777893 SCORE : 1.0\n",
      "[53/1000]\n",
      "- [TRAIN] LOSS : 0.08076699574788411 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.06700234860181808 SCORE : 1.0\n",
      "[54/1000]\n",
      "- [TRAIN] LOSS : 0.07611628539032406 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.06291831284761429 SCORE : 1.0\n",
      "[55/1000]\n",
      "- [TRAIN] LOSS : 0.07181014410323566 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.05914831534028053 SCORE : 1.0\n",
      "[56/1000]\n",
      "- [TRAIN] LOSS : 0.06781368081768353 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.055674053728580475 SCORE : 1.0\n",
      "[57/1000]\n",
      "- [TRAIN] LOSS : 0.06411089044478205 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.052468568086624146 SCORE : 1.0\n",
      "[58/1000]\n",
      "- [TRAIN] LOSS : 0.06068170236216651 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.04951390624046326 SCORE : 1.0\n",
      "[59/1000]\n",
      "- [TRAIN] LOSS : 0.05749835612045394 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.046779122203588486 SCORE : 1.0\n",
      "[60/1000]\n",
      "- [TRAIN] LOSS : 0.05453789606690407 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.044243521988391876 SCORE : 1.0\n",
      "[61/1000]\n",
      "- [TRAIN] LOSS : 0.051781254510084786 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.041890401393175125 SCORE : 1.0\n",
      "[62/1000]\n",
      "- [TRAIN] LOSS : 0.04921200581722789 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.039705246686935425 SCORE : 1.0\n",
      "[63/1000]\n",
      "- [TRAIN] LOSS : 0.04681508532828755 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.037675611674785614 SCORE : 1.0\n",
      "[64/1000]\n",
      "- [TRAIN] LOSS : 0.04457748350169924 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.03578624501824379 SCORE : 1.0\n",
      "[65/1000]\n",
      "- [TRAIN] LOSS : 0.04248671130173736 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.03402547165751457 SCORE : 1.0\n",
      "[66/1000]\n",
      "- [TRAIN] LOSS : 0.04053099391361078 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.03238746523857117 SCORE : 1.0\n",
      "[67/1000]\n",
      "- [TRAIN] LOSS : 0.0386998945226272 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.030861124396324158 SCORE : 1.0\n",
      "[68/1000]\n",
      "- [TRAIN] LOSS : 0.03698457756804095 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.029433276504278183 SCORE : 1.0\n",
      "[69/1000]\n",
      "- [TRAIN] LOSS : 0.03537785034212801 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.028097111731767654 SCORE : 1.0\n",
      "[70/1000]\n",
      "- [TRAIN] LOSS : 0.033869447807470955 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0268461462110281 SCORE : 1.0\n",
      "[71/1000]\n",
      "- [TRAIN] LOSS : 0.03245177326930894 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.02567213773727417 SCORE : 1.0\n",
      "[72/1000]\n",
      "- [TRAIN] LOSS : 0.031117640642656222 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.024569127708673477 SCORE : 1.0\n",
      "[73/1000]\n",
      "- [TRAIN] LOSS : 0.029862981082664594 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.023532111197710037 SCORE : 1.0\n",
      "[74/1000]\n",
      "- [TRAIN] LOSS : 0.0286805998120043 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.02255631610751152 SCORE : 1.0\n",
      "[75/1000]\n",
      "- [TRAIN] LOSS : 0.027564536987079516 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.021637270227074623 SCORE : 1.0\n",
      "[76/1000]\n",
      "- [TRAIN] LOSS : 0.02650986135833793 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.020770804956555367 SCORE : 1.0\n",
      "[77/1000]\n",
      "- [TRAIN] LOSS : 0.025511423953705363 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.019953394308686256 SCORE : 1.0\n",
      "[78/1000]\n",
      "- [TRAIN] LOSS : 0.024568207561969757 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.019181713461875916 SCORE : 1.0\n",
      "[79/1000]\n",
      "- [TRAIN] LOSS : 0.023675611346132226 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.018452048301696777 SCORE : 1.0\n",
      "[80/1000]\n",
      "- [TRAIN] LOSS : 0.022829959065549903 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.017761537805199623 SCORE : 1.0\n",
      "[81/1000]\n",
      "- [TRAIN] LOSS : 0.022027492109272215 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.017107458785176277 SCORE : 1.0\n",
      "[82/1000]\n",
      "- [TRAIN] LOSS : 0.021265395916998386 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.01648705266416073 SCORE : 1.0\n",
      "[83/1000]\n",
      "- [TRAIN] LOSS : 0.020541310517324343 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.01590048149228096 SCORE : 1.0\n",
      "[84/1000]\n",
      "- [TRAIN] LOSS : 0.019853232221470937 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.01534344907850027 SCORE : 1.0\n",
      "[85/1000]\n",
      "- [TRAIN] LOSS : 0.019198659393522475 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.01481431070715189 SCORE : 1.0\n",
      "[86/1000]\n",
      "- [TRAIN] LOSS : 0.018575205674601927 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.01431181188672781 SCORE : 1.0\n",
      "[87/1000]\n",
      "- [TRAIN] LOSS : 0.017980822775926854 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.013833711855113506 SCORE : 1.0\n",
      "[88/1000]\n",
      "- [TRAIN] LOSS : 0.017413757741451263 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.013378445990383625 SCORE : 1.0\n",
      "[89/1000]\n",
      "- [TRAIN] LOSS : 0.016872392036020756 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.012944583781063557 SCORE : 1.0\n",
      "[90/1000]\n",
      "- [TRAIN] LOSS : 0.016355264000594616 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.012530786916613579 SCORE : 1.0\n",
      "[91/1000]\n",
      "- [TRAIN] LOSS : 0.015860957300497427 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.012135803699493408 SCORE : 1.0\n",
      "[92/1000]\n",
      "- [TRAIN] LOSS : 0.015388347932861911 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0117595624178648 SCORE : 1.0\n",
      "[93/1000]\n",
      "- [TRAIN] LOSS : 0.014936225074860785 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.011400775983929634 SCORE : 1.0\n",
      "[94/1000]\n",
      "- [TRAIN] LOSS : 0.01450319815840986 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.01105714775621891 SCORE : 1.0\n",
      "[95/1000]\n",
      "- [TRAIN] LOSS : 0.01408915345867475 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.010728281922638416 SCORE : 1.0\n",
      "[96/1000]\n",
      "- [TRAIN] LOSS : 0.01369296262661616 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.010413573123514652 SCORE : 1.0\n",
      "[97/1000]\n",
      "- [TRAIN] LOSS : 0.013313781935721636 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.010112650692462921 SCORE : 1.0\n",
      "[98/1000]\n",
      "- [TRAIN] LOSS : 0.012949141001121866 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.009824362583458424 SCORE : 1.0\n",
      "[99/1000]\n",
      "- [TRAIN] LOSS : 0.012598733314209513 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.009547810070216656 SCORE : 1.0\n",
      "[100/1000]\n",
      "- [TRAIN] LOSS : 0.012260857762561904 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.009280801750719547 SCORE : 1.0\n",
      "[101/1000]\n",
      "- [TRAIN] LOSS : 0.011938508806957139 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.009024174883961678 SCORE : 1.0\n",
      "[102/1000]\n",
      "- [TRAIN] LOSS : 0.011629030418892702 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00877781305462122 SCORE : 1.0\n",
      "[103/1000]\n",
      "- [TRAIN] LOSS : 0.011331411802934276 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.008541278541088104 SCORE : 1.0\n",
      "[104/1000]\n",
      "- [TRAIN] LOSS : 0.01104450634577208 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.008313407190144062 SCORE : 1.0\n",
      "[105/1000]\n",
      "- [TRAIN] LOSS : 0.010769019317295816 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00809429306536913 SCORE : 1.0\n",
      "[106/1000]\n",
      "- [TRAIN] LOSS : 0.010503583587706089 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.007883511483669281 SCORE : 1.0\n",
      "[107/1000]\n",
      "- [TRAIN] LOSS : 0.01024760916415188 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.007680634967982769 SCORE : 1.0\n",
      "[108/1000]\n",
      "- [TRAIN] LOSS : 0.010000914490471283 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.007485383655875921 SCORE : 1.0\n",
      "[109/1000]\n",
      "- [TRAIN] LOSS : 0.00976289731139938 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.007297412492334843 SCORE : 1.0\n",
      "[110/1000]\n",
      "- [TRAIN] LOSS : 0.009533000075154834 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.007116268388926983 SCORE : 1.0\n",
      "[111/1000]\n",
      "- [TRAIN] LOSS : 0.00931091777359446 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.006941621657460928 SCORE : 1.0\n",
      "[112/1000]\n",
      "- [TRAIN] LOSS : 0.009096277567247549 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.006773018278181553 SCORE : 1.0\n",
      "[113/1000]\n",
      "- [TRAIN] LOSS : 0.008888906799256802 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.006610217038542032 SCORE : 1.0\n",
      "[114/1000]\n",
      "- [TRAIN] LOSS : 0.008688477333635092 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.006452995352447033 SCORE : 1.0\n",
      "[115/1000]\n",
      "- [TRAIN] LOSS : 0.008494628231144614 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.006301134824752808 SCORE : 1.0\n",
      "[116/1000]\n",
      "- [TRAIN] LOSS : 0.008307078801509406 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.006154388654977083 SCORE : 1.0\n",
      "[117/1000]\n",
      "- [TRAIN] LOSS : 0.008125544784383642 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.006012528669089079 SCORE : 1.0\n",
      "[118/1000]\n",
      "- [TRAIN] LOSS : 0.007949769548657868 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.005875348579138517 SCORE : 1.0\n",
      "[119/1000]\n",
      "- [TRAIN] LOSS : 0.007779504327724378 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0057426332496106625 SCORE : 1.0\n",
      "[120/1000]\n",
      "- [TRAIN] LOSS : 0.0076144249695870615 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.005614009685814381 SCORE : 1.0\n",
      "[121/1000]\n",
      "- [TRAIN] LOSS : 0.007454671250242326 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.005489376373589039 SCORE : 1.0\n",
      "[122/1000]\n",
      "- [TRAIN] LOSS : 0.007299929495073027 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.005368695128709078 SCORE : 1.0\n",
      "[123/1000]\n",
      "- [TRAIN] LOSS : 0.007149697333160374 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.005251477938145399 SCORE : 1.0\n",
      "[124/1000]\n",
      "- [TRAIN] LOSS : 0.007004326157685783 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.005137830041348934 SCORE : 1.0\n",
      "[125/1000]\n",
      "- [TRAIN] LOSS : 0.00686342129483819 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.005027748178690672 SCORE : 1.0\n",
      "[126/1000]\n",
      "- [TRAIN] LOSS : 0.006726687179050512 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0049211010336875916 SCORE : 1.0\n",
      "[127/1000]\n",
      "- [TRAIN] LOSS : 0.006593921972024772 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0048177530989050865 SCORE : 1.0\n",
      "[128/1000]\n",
      "- [TRAIN] LOSS : 0.006464922645439704 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.004717550706118345 SCORE : 1.0\n",
      "[129/1000]\n",
      "- [TRAIN] LOSS : 0.006339564169239666 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0046203588135540485 SCORE : 1.0\n",
      "[130/1000]\n",
      "- [TRAIN] LOSS : 0.0062177054221845334 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.004526031669229269 SCORE : 1.0\n",
      "[131/1000]\n",
      "- [TRAIN] LOSS : 0.00609921314753592 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.004434469621628523 SCORE : 1.0\n",
      "[132/1000]\n",
      "- [TRAIN] LOSS : 0.005984016513038013 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.004345572553575039 SCORE : 1.0\n",
      "[133/1000]\n",
      "- [TRAIN] LOSS : 0.0058719424479123615 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.004259241279214621 SCORE : 1.0\n",
      "[134/1000]\n",
      "- [TRAIN] LOSS : 0.005762858781963587 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0041753253899514675 SCORE : 1.0\n",
      "[135/1000]\n",
      "- [TRAIN] LOSS : 0.005656741611245606 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.004093747120350599 SCORE : 1.0\n",
      "[136/1000]\n",
      "- [TRAIN] LOSS : 0.005553411449202233 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.004014402627944946 SCORE : 1.0\n",
      "[137/1000]\n",
      "- [TRAIN] LOSS : 0.005452809105109837 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.003937202971428633 SCORE : 1.0\n",
      "[138/1000]\n",
      "- [TRAIN] LOSS : 0.005354883123396171 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0038620964623987675 SCORE : 1.0\n",
      "[139/1000]\n",
      "- [TRAIN] LOSS : 0.005259478982124064 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0037890118546783924 SCORE : 1.0\n",
      "[140/1000]\n",
      "- [TRAIN] LOSS : 0.005166558367717598 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0037179174832999706 SCORE : 1.0\n",
      "[141/1000]\n",
      "- [TRAIN] LOSS : 0.005075978322161568 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.003648711834102869 SCORE : 1.0\n",
      "[142/1000]\n",
      "- [TRAIN] LOSS : 0.004987669694754813 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0035813176073133945 SCORE : 1.0\n",
      "[143/1000]\n",
      "- [TRAIN] LOSS : 0.004901551641523838 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0035156630910933018 SCORE : 1.0\n",
      "[144/1000]\n",
      "- [TRAIN] LOSS : 0.004817556900282701 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.003451672149822116 SCORE : 1.0\n",
      "[145/1000]\n",
      "- [TRAIN] LOSS : 0.004735695586229364 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.003389351535588503 SCORE : 1.0\n",
      "[146/1000]\n",
      "- [TRAIN] LOSS : 0.004655801070233186 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0033286213874816895 SCORE : 1.0\n",
      "[147/1000]\n",
      "- [TRAIN] LOSS : 0.004577841273405486 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.003269428852945566 SCORE : 1.0\n",
      "[148/1000]\n",
      "- [TRAIN] LOSS : 0.0045017507962054676 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0032117099035531282 SCORE : 1.0\n",
      "[149/1000]\n",
      "- [TRAIN] LOSS : 0.004427461496864756 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.003155422629788518 SCORE : 1.0\n",
      "[150/1000]\n",
      "- [TRAIN] LOSS : 0.004354935268768006 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0031005057971924543 SCORE : 1.0\n",
      "[151/1000]\n",
      "- [TRAIN] LOSS : 0.004284107307386067 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0030469365883618593 SCORE : 1.0\n",
      "[152/1000]\n",
      "- [TRAIN] LOSS : 0.004214874559289051 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.002994531998410821 SCORE : 1.0\n",
      "[153/1000]\n",
      "- [TRAIN] LOSS : 0.00414738916636755 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0029434196185320616 SCORE : 1.0\n",
      "[154/1000]\n",
      "- [TRAIN] LOSS : 0.004081497938993077 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0028935500886291265 SCORE : 1.0\n",
      "[155/1000]\n",
      "- [TRAIN] LOSS : 0.004017119981451995 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0028448805678635836 SCORE : 1.0\n",
      "[156/1000]\n",
      "- [TRAIN] LOSS : 0.0039542016650860505 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.002797359600663185 SCORE : 1.0\n",
      "[157/1000]\n",
      "- [TRAIN] LOSS : 0.00389268493745476 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0027509897481650114 SCORE : 1.0\n",
      "[158/1000]\n",
      "- [TRAIN] LOSS : 0.0038325245906081465 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0027056951075792313 SCORE : 1.0\n",
      "[159/1000]\n",
      "- [TRAIN] LOSS : 0.0037736941335929763 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.002661455888301134 SCORE : 1.0\n",
      "[160/1000]\n",
      "- [TRAIN] LOSS : 0.0037161291499311724 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0026181878056377172 SCORE : 1.0\n",
      "[161/1000]\n",
      "- [TRAIN] LOSS : 0.0036598624428734183 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0025758652482181787 SCORE : 1.0\n",
      "[162/1000]\n",
      "- [TRAIN] LOSS : 0.0036048305919393897 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00253451825119555 SCORE : 1.0\n",
      "[163/1000]\n",
      "- [TRAIN] LOSS : 0.0035509758163243532 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0024940979201346636 SCORE : 1.0\n",
      "[164/1000]\n",
      "- [TRAIN] LOSS : 0.0034981855812172094 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0024545062333345413 SCORE : 1.0\n",
      "[165/1000]\n",
      "- [TRAIN] LOSS : 0.00344660885942479 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0024157031439244747 SCORE : 1.0\n",
      "[166/1000]\n",
      "- [TRAIN] LOSS : 0.003396183821476168 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0023777515161782503 SCORE : 1.0\n",
      "[167/1000]\n",
      "- [TRAIN] LOSS : 0.0033468362202660907 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.002340627135708928 SCORE : 1.0\n",
      "[168/1000]\n",
      "- [TRAIN] LOSS : 0.003298534610722628 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.002304323250427842 SCORE : 1.0\n",
      "[169/1000]\n",
      "- [TRAIN] LOSS : 0.0032512514541546502 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0022688212338835 SCORE : 1.0\n",
      "[170/1000]\n",
      "- [TRAIN] LOSS : 0.0032049198764272863 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.002234100131317973 SCORE : 1.0\n",
      "[171/1000]\n",
      "- [TRAIN] LOSS : 0.003159517073072493 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0022001343313604593 SCORE : 1.0\n",
      "[172/1000]\n",
      "- [TRAIN] LOSS : 0.0031150271081262166 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0021668877452611923 SCORE : 1.0\n",
      "[173/1000]\n",
      "- [TRAIN] LOSS : 0.0030714202180711758 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0021343606058508158 SCORE : 1.0\n",
      "[174/1000]\n",
      "- [TRAIN] LOSS : 0.0030286649449004065 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0021025105379521847 SCORE : 1.0\n",
      "[175/1000]\n",
      "- [TRAIN] LOSS : 0.0029867544459799924 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0020713272970169783 SCORE : 1.0\n",
      "[176/1000]\n",
      "- [TRAIN] LOSS : 0.0029456628512384165 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0020407794509083033 SCORE : 1.0\n",
      "[177/1000]\n",
      "- [TRAIN] LOSS : 0.002905352325696084 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0020108611788600683 SCORE : 1.0\n",
      "[178/1000]\n",
      "- [TRAIN] LOSS : 0.002865829815467199 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0019815547857433558 SCORE : 1.0\n",
      "[179/1000]\n",
      "- [TRAIN] LOSS : 0.0028270634486236507 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0019528340781107545 SCORE : 1.0\n",
      "[180/1000]\n",
      "- [TRAIN] LOSS : 0.0027890257123443815 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0019246850861236453 SCORE : 1.0\n",
      "[181/1000]\n",
      "- [TRAIN] LOSS : 0.0027517073710138598 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0018970990786328912 SCORE : 1.0\n",
      "[182/1000]\n",
      "- [TRAIN] LOSS : 0.002715099460652305 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0018700419459491968 SCORE : 1.0\n",
      "[183/1000]\n",
      "- [TRAIN] LOSS : 0.0026791312395491535 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0018434819066897035 SCORE : 1.0\n",
      "[184/1000]\n",
      "- [TRAIN] LOSS : 0.0026439070546378693 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0018174091819673777 SCORE : 1.0\n",
      "[185/1000]\n",
      "- [TRAIN] LOSS : 0.002609358401969075 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0017918302910402417 SCORE : 1.0\n",
      "[186/1000]\n",
      "- [TRAIN] LOSS : 0.0025754534484197697 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0017667548963800073 SCORE : 1.0\n",
      "[187/1000]\n",
      "- [TRAIN] LOSS : 0.002542159584764805 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0017421437660232186 SCORE : 1.0\n",
      "[188/1000]\n",
      "- [TRAIN] LOSS : 0.002509495127014816 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0017179454443976283 SCORE : 1.0\n",
      "[189/1000]\n",
      "- [TRAIN] LOSS : 0.0024774170791109404 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.001694159465841949 SCORE : 1.0\n",
      "[190/1000]\n",
      "- [TRAIN] LOSS : 0.002445981126382119 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0016708209877833724 SCORE : 1.0\n",
      "[191/1000]\n",
      "- [TRAIN] LOSS : 0.002415129268128011 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0016479222103953362 SCORE : 1.0\n",
      "[192/1000]\n",
      "- [TRAIN] LOSS : 0.002384828222501609 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0016254910733550787 SCORE : 1.0\n",
      "[193/1000]\n",
      "- [TRAIN] LOSS : 0.0023550662121528555 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.001603480544872582 SCORE : 1.0\n",
      "[194/1000]\n",
      "- [TRAIN] LOSS : 0.0023258212798585496 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0015818929532542825 SCORE : 1.0\n",
      "[195/1000]\n",
      "- [TRAIN] LOSS : 0.002297082954707245 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0015607140958309174 SCORE : 1.0\n",
      "[196/1000]\n",
      "- [TRAIN] LOSS : 0.0022688358181363177 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.001539932214654982 SCORE : 1.0\n",
      "[197/1000]\n",
      "- [TRAIN] LOSS : 0.002241069528584679 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.001519532292149961 SCORE : 1.0\n",
      "[198/1000]\n",
      "- [TRAIN] LOSS : 0.0022137571423728433 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0014994677621871233 SCORE : 1.0\n",
      "[199/1000]\n",
      "- [TRAIN] LOSS : 0.0021869094408531156 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.001479702303186059 SCORE : 1.0\n",
      "[200/1000]\n",
      "- [TRAIN] LOSS : 0.0021605789467381933 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.001460283761844039 SCORE : 1.0\n",
      "[201/1000]\n",
      "- [TRAIN] LOSS : 0.002134715465621816 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0014412269229069352 SCORE : 1.0\n",
      "[202/1000]\n",
      "- [TRAIN] LOSS : 0.0021093018068414596 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.001422515488229692 SCORE : 1.0\n",
      "[203/1000]\n",
      "- [TRAIN] LOSS : 0.002084333352589359 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0014041615650057793 SCORE : 1.0\n",
      "[204/1000]\n",
      "- [TRAIN] LOSS : 0.0020597667963657943 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0013861429179087281 SCORE : 1.0\n",
      "[205/1000]\n",
      "- [TRAIN] LOSS : 0.0020355996675789356 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.001368452445603907 SCORE : 1.0\n",
      "[206/1000]\n",
      "- [TRAIN] LOSS : 0.002011816612341338 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0013510669814422727 SCORE : 1.0\n",
      "[207/1000]\n",
      "- [TRAIN] LOSS : 0.0019884210002298155 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0013339921133592725 SCORE : 1.0\n",
      "[208/1000]\n",
      "- [TRAIN] LOSS : 0.0019653901173215774 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0013172070030122995 SCORE : 1.0\n",
      "[209/1000]\n",
      "- [TRAIN] LOSS : 0.0019427448795694443 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0013006955850869417 SCORE : 1.0\n",
      "[210/1000]\n",
      "- [TRAIN] LOSS : 0.0019204519663213028 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0012844763696193695 SCORE : 1.0\n",
      "[211/1000]\n",
      "- [TRAIN] LOSS : 0.0018985197271427347 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0012685165274888277 SCORE : 1.0\n",
      "[212/1000]\n",
      "- [TRAIN] LOSS : 0.0018769350265049273 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.001252835732884705 SCORE : 1.0\n",
      "[213/1000]\n",
      "- [TRAIN] LOSS : 0.0018556374448558523 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.001237372518517077 SCORE : 1.0\n",
      "[214/1000]\n",
      "- [TRAIN] LOSS : 0.0018347293436009851 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0012221444630995393 SCORE : 1.0\n",
      "[215/1000]\n",
      "- [TRAIN] LOSS : 0.0018141749767690068 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0012071523815393448 SCORE : 1.0\n",
      "[216/1000]\n",
      "- [TRAIN] LOSS : 0.0017939551164292628 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0011924220016226172 SCORE : 1.0\n",
      "[217/1000]\n",
      "- [TRAIN] LOSS : 0.0017740486849409838 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.001177932252176106 SCORE : 1.0\n",
      "[218/1000]\n",
      "- [TRAIN] LOSS : 0.0017544654353211324 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0011636837152764201 SCORE : 1.0\n",
      "[219/1000]\n",
      "- [TRAIN] LOSS : 0.001735168625600636 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0011496905935928226 SCORE : 1.0\n",
      "[220/1000]\n",
      "- [TRAIN] LOSS : 0.001716160280112591 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0011359115596860647 SCORE : 1.0\n",
      "[221/1000]\n",
      "- [TRAIN] LOSS : 0.0016974404958697658 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0011223728070035577 SCORE : 1.0\n",
      "[222/1000]\n",
      "- [TRAIN] LOSS : 0.0016790003671000402 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0011090511688962579 SCORE : 1.0\n",
      "[223/1000]\n",
      "- [TRAIN] LOSS : 0.0016608332969351774 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0010959254577755928 SCORE : 1.0\n",
      "[224/1000]\n",
      "- [TRAIN] LOSS : 0.0016429030025998752 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0010829729726538062 SCORE : 1.0\n",
      "[225/1000]\n",
      "- [TRAIN] LOSS : 0.001625278272614297 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.001070216647349298 SCORE : 1.0\n",
      "[226/1000]\n",
      "- [TRAIN] LOSS : 0.0016079311673012045 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0010576574131846428 SCORE : 1.0\n",
      "[227/1000]\n",
      "- [TRAIN] LOSS : 0.0015908424263923531 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.001045307726599276 SCORE : 1.0\n",
      "[228/1000]\n",
      "- [TRAIN] LOSS : 0.001574013621494588 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0010331652592867613 SCORE : 1.0\n",
      "[229/1000]\n",
      "- [TRAIN] LOSS : 0.0015574216506340438 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0010212106863036752 SCORE : 1.0\n",
      "[230/1000]\n",
      "- [TRAIN] LOSS : 0.0015410818612306481 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0010094430763274431 SCORE : 1.0\n",
      "[231/1000]\n",
      "- [TRAIN] LOSS : 0.001524960369958232 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0009978761663660407 SCORE : 1.0\n",
      "[232/1000]\n",
      "- [TRAIN] LOSS : 0.0015090751112438738 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0009864752646535635 SCORE : 1.0\n",
      "[233/1000]\n",
      "- [TRAIN] LOSS : 0.001493411571977453 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0009752606274560094 SCORE : 1.0\n",
      "[234/1000]\n",
      "- [TRAIN] LOSS : 0.0014779620428776576 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0009642052464187145 SCORE : 1.0\n",
      "[235/1000]\n",
      "- [TRAIN] LOSS : 0.0014627384371124208 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0009533336269669235 SCORE : 1.0\n",
      "[236/1000]\n",
      "- [TRAIN] LOSS : 0.0014477207506489423 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0009426191681995988 SCORE : 1.0\n",
      "[237/1000]\n",
      "- [TRAIN] LOSS : 0.0014329251134768128 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0009320449898950756 SCORE : 1.0\n",
      "[238/1000]\n",
      "- [TRAIN] LOSS : 0.0014183334391822831 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.000921625760383904 SCORE : 1.0\n",
      "[239/1000]\n",
      "- [TRAIN] LOSS : 0.0014039523181660722 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0009113688720390201 SCORE : 1.0\n",
      "[240/1000]\n",
      "- [TRAIN] LOSS : 0.0013897710628548844 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0009012616937980056 SCORE : 1.0\n",
      "[241/1000]\n",
      "- [TRAIN] LOSS : 0.0013757834159251717 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0008913064375519753 SCORE : 1.0\n",
      "[242/1000]\n",
      "- [TRAIN] LOSS : 0.0013619830877157962 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0008814994944259524 SCORE : 1.0\n",
      "[243/1000]\n",
      "- [TRAIN] LOSS : 0.0013483700264866154 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0008718402241356671 SCORE : 1.0\n",
      "[244/1000]\n",
      "- [TRAIN] LOSS : 0.0013349357403866532 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0008623235626146197 SCORE : 1.0\n",
      "[245/1000]\n",
      "- [TRAIN] LOSS : 0.0013216882588393572 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0008529456099495292 SCORE : 1.0\n",
      "[246/1000]\n",
      "- [TRAIN] LOSS : 0.0013086117202571284 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0008436983334831893 SCORE : 1.0\n",
      "[247/1000]\n",
      "- [TRAIN] LOSS : 0.0012957083365310812 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0008345896494574845 SCORE : 1.0\n",
      "[248/1000]\n",
      "- [TRAIN] LOSS : 0.0012829845622440593 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0008255990105681121 SCORE : 1.0\n",
      "[249/1000]\n",
      "- [TRAIN] LOSS : 0.001270423620654684 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0008167354390025139 SCORE : 1.0\n",
      "[250/1000]\n",
      "- [TRAIN] LOSS : 0.0012580224784970698 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0008080076077021658 SCORE : 1.0\n",
      "[251/1000]\n",
      "- [TRAIN] LOSS : 0.0012457912218653494 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.000799392641056329 SCORE : 1.0\n",
      "[252/1000]\n",
      "- [TRAIN] LOSS : 0.0012337085564569053 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0007909007254056633 SCORE : 1.0\n",
      "[253/1000]\n",
      "- [TRAIN] LOSS : 0.001221791921933699 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.000782524875830859 SCORE : 1.0\n",
      "[254/1000]\n",
      "- [TRAIN] LOSS : 0.0012100309379295343 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0007742713205516338 SCORE : 1.0\n",
      "[255/1000]\n",
      "- [TRAIN] LOSS : 0.0011984132029788776 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0007661227136850357 SCORE : 1.0\n",
      "[256/1000]\n",
      "- [TRAIN] LOSS : 0.0011869485768127358 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0007580927922390401 SCORE : 1.0\n",
      "[257/1000]\n",
      "- [TRAIN] LOSS : 0.0011756256410282934 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.000750193779822439 SCORE : 1.0\n",
      "[258/1000]\n",
      "- [TRAIN] LOSS : 0.0011644549764848005 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0007423995994031429 SCORE : 1.0\n",
      "[259/1000]\n",
      "- [TRAIN] LOSS : 0.0011534151853993535 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0007347213104367256 SCORE : 1.0\n",
      "[260/1000]\n",
      "- [TRAIN] LOSS : 0.0011425191640026039 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0007271422655321658 SCORE : 1.0\n",
      "[261/1000]\n",
      "- [TRAIN] LOSS : 0.0011317613017227915 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0007196603110060096 SCORE : 1.0\n",
      "[262/1000]\n",
      "- [TRAIN] LOSS : 0.0011211352377560818 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00071229028981179 SCORE : 1.0\n",
      "[263/1000]\n",
      "- [TRAIN] LOSS : 0.0011106427247998202 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0007050029234960675 SCORE : 1.0\n",
      "[264/1000]\n",
      "- [TRAIN] LOSS : 0.0011002804029784682 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0006978224846534431 SCORE : 1.0\n",
      "[265/1000]\n",
      "- [TRAIN] LOSS : 0.0010900437967696537 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0006907316274009645 SCORE : 1.0\n",
      "[266/1000]\n",
      "- [TRAIN] LOSS : 0.0010799409841032077 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.000683734193444252 SCORE : 1.0\n",
      "[267/1000]\n",
      "- [TRAIN] LOSS : 0.001069961639586836 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0006768293678760529 SCORE : 1.0\n",
      "[268/1000]\n",
      "- [TRAIN] LOSS : 0.0010600985939769696 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0006700141238979995 SCORE : 1.0\n",
      "[269/1000]\n",
      "- [TRAIN] LOSS : 0.001050351097041534 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0006632932345382869 SCORE : 1.0\n",
      "[270/1000]\n",
      "- [TRAIN] LOSS : 0.001040733648955615 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00065664853900671 SCORE : 1.0\n",
      "[271/1000]\n",
      "- [TRAIN] LOSS : 0.001031233954967724 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0006500970339402556 SCORE : 1.0\n",
      "[272/1000]\n",
      "- [TRAIN] LOSS : 0.0010218354873359203 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0006436224211938679 SCORE : 1.0\n",
      "[273/1000]\n",
      "- [TRAIN] LOSS : 0.0010125607950612903 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0006372377392835915 SCORE : 1.0\n",
      "[274/1000]\n",
      "- [TRAIN] LOSS : 0.0010033960829281972 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0006309300079010427 SCORE : 1.0\n",
      "[275/1000]\n",
      "- [TRAIN] LOSS : 0.0009943409564180507 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0006247058627195656 SCORE : 1.0\n",
      "[276/1000]\n",
      "- [TRAIN] LOSS : 0.0009853850933723152 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0006185608799569309 SCORE : 1.0\n",
      "[277/1000]\n",
      "- [TRAIN] LOSS : 0.0009765438800160256 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0006125056534074247 SCORE : 1.0\n",
      "[278/1000]\n",
      "- [TRAIN] LOSS : 0.0009678020271369152 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0006065027555450797 SCORE : 1.0\n",
      "[279/1000]\n",
      "- [TRAIN] LOSS : 0.00095916040138238 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0006005787872709334 SCORE : 1.0\n",
      "[280/1000]\n",
      "- [TRAIN] LOSS : 0.0009506230449510945 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0005947266472503543 SCORE : 1.0\n",
      "[281/1000]\n",
      "- [TRAIN] LOSS : 0.0009421916976053682 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0005889541353099048 SCORE : 1.0\n",
      "[282/1000]\n",
      "- [TRAIN] LOSS : 0.0009338524606492785 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0005832422175444663 SCORE : 1.0\n",
      "[283/1000]\n",
      "- [TRAIN] LOSS : 0.0009256240155082196 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.000577615515794605 SCORE : 1.0\n",
      "[284/1000]\n",
      "- [TRAIN] LOSS : 0.0009174737012169013 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0005720531917177141 SCORE : 1.0\n",
      "[285/1000]\n",
      "- [TRAIN] LOSS : 0.000909424910787493 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0005665572243742645 SCORE : 1.0\n",
      "[286/1000]\n",
      "- [TRAIN] LOSS : 0.0009014648029632452 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.000561120396014303 SCORE : 1.0\n",
      "[287/1000]\n",
      "- [TRAIN] LOSS : 0.0008935994507434467 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0005557663389481604 SCORE : 1.0\n",
      "[288/1000]\n",
      "- [TRAIN] LOSS : 0.0008858150492111841 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0005504688597284257 SCORE : 1.0\n",
      "[289/1000]\n",
      "- [TRAIN] LOSS : 0.0008781329217729055 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0005452336627058685 SCORE : 1.0\n",
      "[290/1000]\n",
      "- [TRAIN] LOSS : 0.000870524931492077 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0005400694790296257 SCORE : 1.0\n",
      "[291/1000]\n",
      "- [TRAIN] LOSS : 0.0008630090839384744 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0005349649582058191 SCORE : 1.0\n",
      "[292/1000]\n",
      "- [TRAIN] LOSS : 0.0008555676742819034 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0005299183540046215 SCORE : 1.0\n",
      "[293/1000]\n",
      "- [TRAIN] LOSS : 0.0008482233582374951 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0005249121459200978 SCORE : 1.0\n",
      "[294/1000]\n",
      "- [TRAIN] LOSS : 0.0008409695454045302 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0005199838778935373 SCORE : 1.0\n",
      "[295/1000]\n",
      "- [TRAIN] LOSS : 0.0008337877548506691 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0005151085206307471 SCORE : 1.0\n",
      "[296/1000]\n",
      "- [TRAIN] LOSS : 0.0008266829859672321 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.000510288227815181 SCORE : 1.0\n",
      "[297/1000]\n",
      "- [TRAIN] LOSS : 0.0008196666070337718 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.000505526433698833 SCORE : 1.0\n",
      "[298/1000]\n",
      "- [TRAIN] LOSS : 0.0008127219658086284 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0005008191801607609 SCORE : 1.0\n",
      "[299/1000]\n",
      "- [TRAIN] LOSS : 0.0008058521958042143 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0004961689119227231 SCORE : 1.0\n",
      "[300/1000]\n",
      "- [TRAIN] LOSS : 0.0007990597853980338 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0004915794124826789 SCORE : 1.0\n",
      "[301/1000]\n",
      "- [TRAIN] LOSS : 0.0007923397966401859 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00048704538494348526 SCORE : 1.0\n",
      "[302/1000]\n",
      "- [TRAIN] LOSS : 0.0007856901906456591 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0004825614742003381 SCORE : 1.0\n",
      "[303/1000]\n",
      "- [TRAIN] LOSS : 0.0007791195239406079 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0004781117313541472 SCORE : 1.0\n",
      "[304/1000]\n",
      "- [TRAIN] LOSS : 0.0007726176603076359 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0004737305862363428 SCORE : 1.0\n",
      "[305/1000]\n",
      "- [TRAIN] LOSS : 0.0007661935443239701 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0004693899827543646 SCORE : 1.0\n",
      "[306/1000]\n",
      "- [TRAIN] LOSS : 0.0007598285851094665 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.000465093384264037 SCORE : 1.0\n",
      "[307/1000]\n",
      "- [TRAIN] LOSS : 0.0007535466187012693 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00046086215297691524 SCORE : 1.0\n",
      "[308/1000]\n",
      "- [TRAIN] LOSS : 0.0007473175468880476 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00045667882659472525 SCORE : 1.0\n",
      "[309/1000]\n",
      "- [TRAIN] LOSS : 0.0007411621530385067 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00045253700227476656 SCORE : 1.0\n",
      "[310/1000]\n",
      "- [TRAIN] LOSS : 0.0007350689508408929 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00044843737850897014 SCORE : 1.0\n",
      "[311/1000]\n",
      "- [TRAIN] LOSS : 0.0007290418725460768 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0004444019286893308 SCORE : 1.0\n",
      "[312/1000]\n",
      "- [TRAIN] LOSS : 0.0007230756632957815 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0004403951461426914 SCORE : 1.0\n",
      "[313/1000]\n",
      "- [TRAIN] LOSS : 0.0007171650973355605 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00043642925447784364 SCORE : 1.0\n",
      "[314/1000]\n",
      "- [TRAIN] LOSS : 0.000711331192481642 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00043253268813714385 SCORE : 1.0\n",
      "[315/1000]\n",
      "- [TRAIN] LOSS : 0.0007055547208033709 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00042864936403930187 SCORE : 1.0\n",
      "[316/1000]\n",
      "- [TRAIN] LOSS : 0.0006998375966860396 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0004248279146850109 SCORE : 1.0\n",
      "[317/1000]\n",
      "- [TRAIN] LOSS : 0.0006941765766694314 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00042105079046450555 SCORE : 1.0\n",
      "[318/1000]\n",
      "- [TRAIN] LOSS : 0.0006885710026836023 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0004173030029051006 SCORE : 1.0\n",
      "[319/1000]\n",
      "- [TRAIN] LOSS : 0.0006830342156010576 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00041360800969414413 SCORE : 1.0\n",
      "[320/1000]\n",
      "- [TRAIN] LOSS : 0.0006775445848082503 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.000409953499911353 SCORE : 1.0\n",
      "[321/1000]\n",
      "- [TRAIN] LOSS : 0.000672114843231005 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0004063350206706673 SCORE : 1.0\n",
      "[322/1000]\n",
      "- [TRAIN] LOSS : 0.0006667358878379067 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0004027626127935946 SCORE : 1.0\n",
      "[323/1000]\n",
      "- [TRAIN] LOSS : 0.0006614189122855249 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00039921942516230047 SCORE : 1.0\n",
      "[324/1000]\n",
      "- [TRAIN] LOSS : 0.00065614906391905 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00039572868263348937 SCORE : 1.0\n",
      "[325/1000]\n",
      "- [TRAIN] LOSS : 0.0006509361798331762 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00039225423824973404 SCORE : 1.0\n",
      "[326/1000]\n",
      "- [TRAIN] LOSS : 0.0006457729614339769 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0003888404171448201 SCORE : 1.0\n",
      "[327/1000]\n",
      "- [TRAIN] LOSS : 0.0006406665844325391 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0003854552924167365 SCORE : 1.0\n",
      "[328/1000]\n",
      "- [TRAIN] LOSS : 0.0006356040264816127 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00038211102946661413 SCORE : 1.0\n",
      "[329/1000]\n",
      "- [TRAIN] LOSS : 0.0006305918893000732 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0003787972964346409 SCORE : 1.0\n",
      "[330/1000]\n",
      "- [TRAIN] LOSS : 0.0006256392160947952 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0003755181678570807 SCORE : 1.0\n",
      "[331/1000]\n",
      "- [TRAIN] LOSS : 0.0006207245686608884 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0003722753026522696 SCORE : 1.0\n",
      "[332/1000]\n",
      "- [TRAIN] LOSS : 0.0006158600380230281 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0003690621233545244 SCORE : 1.0\n",
      "[333/1000]\n",
      "- [TRAIN] LOSS : 0.0006110448044233231 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0003658926871139556 SCORE : 1.0\n",
      "[334/1000]\n",
      "- [TRAIN] LOSS : 0.0006062804750399664 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0003627479891292751 SCORE : 1.0\n",
      "[335/1000]\n",
      "- [TRAIN] LOSS : 0.0006015585337687904 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0003596502647269517 SCORE : 1.0\n",
      "[336/1000]\n",
      "- [TRAIN] LOSS : 0.0005968917297044148 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00035657474654726684 SCORE : 1.0\n",
      "[337/1000]\n",
      "- [TRAIN] LOSS : 0.0005922559422389087 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0003535297582857311 SCORE : 1.0\n",
      "[338/1000]\n",
      "- [TRAIN] LOSS : 0.0005876754779213419 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0003505194035824388 SCORE : 1.0\n",
      "[339/1000]\n",
      "- [TRAIN] LOSS : 0.0005831320142735624 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00034753052750602365 SCORE : 1.0\n",
      "[340/1000]\n",
      "- [TRAIN] LOSS : 0.0005786435099758415 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00034459095331840217 SCORE : 1.0\n",
      "[341/1000]\n",
      "- [TRAIN] LOSS : 0.000574184604273695 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0003416702675167471 SCORE : 1.0\n",
      "[342/1000]\n",
      "- [TRAIN] LOSS : 0.000569779927092087 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0003387816541362554 SCORE : 1.0\n",
      "[343/1000]\n",
      "- [TRAIN] LOSS : 0.0005654093046258721 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0003359160909894854 SCORE : 1.0\n",
      "[344/1000]\n",
      "- [TRAIN] LOSS : 0.0005610852191845576 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00033307215198874474 SCORE : 1.0\n",
      "[345/1000]\n",
      "- [TRAIN] LOSS : 0.0005568188676584719 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00033025216544047 SCORE : 1.0\n",
      "[346/1000]\n",
      "- [TRAIN] LOSS : 0.0005525790976308701 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0003274721675552428 SCORE : 1.0\n",
      "[347/1000]\n",
      "- [TRAIN] LOSS : 0.0005483890498807239 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00032471533631905913 SCORE : 1.0\n",
      "[348/1000]\n",
      "- [TRAIN] LOSS : 0.0005442432043815239 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00032198833650909364 SCORE : 1.0\n",
      "[349/1000]\n",
      "- [TRAIN] LOSS : 0.0005401329156787446 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00031929646502248943 SCORE : 1.0\n",
      "[350/1000]\n",
      "- [TRAIN] LOSS : 0.0005360586461999143 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00031663067056797445 SCORE : 1.0\n",
      "[351/1000]\n",
      "- [TRAIN] LOSS : 0.0005320262102436067 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00031398405553773046 SCORE : 1.0\n",
      "[352/1000]\n",
      "- [TRAIN] LOSS : 0.0005280334072368634 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0003113874699920416 SCORE : 1.0\n",
      "[353/1000]\n",
      "- [TRAIN] LOSS : 0.0005240753687556005 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0003088034864049405 SCORE : 1.0\n",
      "[354/1000]\n",
      "- [TRAIN] LOSS : 0.0005201479863090855 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0003062449104618281 SCORE : 1.0\n",
      "[355/1000]\n",
      "- [TRAIN] LOSS : 0.0005162651068530977 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0003037096466869116 SCORE : 1.0\n",
      "[356/1000]\n",
      "- [TRAIN] LOSS : 0.0005124138373907448 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00030121259624138474 SCORE : 1.0\n",
      "[357/1000]\n",
      "- [TRAIN] LOSS : 0.0005085993567869688 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0002987324842251837 SCORE : 1.0\n",
      "[358/1000]\n",
      "- [TRAIN] LOSS : 0.000504820355369399 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0002962724829558283 SCORE : 1.0\n",
      "[359/1000]\n",
      "- [TRAIN] LOSS : 0.0005010786569780774 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0002938412071671337 SCORE : 1.0\n",
      "[360/1000]\n",
      "- [TRAIN] LOSS : 0.0004973705201539107 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00029142809216864407 SCORE : 1.0\n",
      "[361/1000]\n",
      "- [TRAIN] LOSS : 0.0004936945737831087 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00028904559439979494 SCORE : 1.0\n",
      "[362/1000]\n",
      "- [TRAIN] LOSS : 0.0004900514177279547 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0002866871654987335 SCORE : 1.0\n",
      "[363/1000]\n",
      "- [TRAIN] LOSS : 0.00048644609422707517 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0002843574620783329 SCORE : 1.0\n",
      "[364/1000]\n",
      "- [TRAIN] LOSS : 0.0004828717929841433 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00028204143745824695 SCORE : 1.0\n",
      "[365/1000]\n",
      "- [TRAIN] LOSS : 0.0004793297452528754 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00027975617558695376 SCORE : 1.0\n",
      "[366/1000]\n",
      "- [TRAIN] LOSS : 0.00047581804796613543 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0002774798485916108 SCORE : 1.0\n",
      "[367/1000]\n",
      "- [TRAIN] LOSS : 0.0004723380196891311 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0002752430154941976 SCORE : 1.0\n",
      "[368/1000]\n",
      "- [TRAIN] LOSS : 0.0004688894882241988 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00027301994850859046 SCORE : 1.0\n",
      "[369/1000]\n",
      "- [TRAIN] LOSS : 0.00046547586599545967 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0002708122774492949 SCORE : 1.0\n",
      "[370/1000]\n",
      "- [TRAIN] LOSS : 0.00046208043527763546 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0002686285297386348 SCORE : 1.0\n",
      "[371/1000]\n",
      "- [TRAIN] LOSS : 0.00045872685991020664 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0002664644562173635 SCORE : 1.0\n",
      "[372/1000]\n",
      "- [TRAIN] LOSS : 0.00045540104151263624 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0002643394109327346 SCORE : 1.0\n",
      "[373/1000]\n",
      "- [TRAIN] LOSS : 0.0004521098962868564 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00026222356245853007 SCORE : 1.0\n",
      "[374/1000]\n",
      "- [TRAIN] LOSS : 0.00044884076891725674 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0002601229934953153 SCORE : 1.0\n",
      "[375/1000]\n",
      "- [TRAIN] LOSS : 0.0004455969828995876 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00025804771576076746 SCORE : 1.0\n",
      "[376/1000]\n",
      "- [TRAIN] LOSS : 0.0004423889202169246 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00025598102365620434 SCORE : 1.0\n",
      "[377/1000]\n",
      "- [TRAIN] LOSS : 0.00043920920628200594 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.000253948470344767 SCORE : 1.0\n",
      "[378/1000]\n",
      "- [TRAIN] LOSS : 0.0004360562096634466 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00025193553301505744 SCORE : 1.0\n",
      "[379/1000]\n",
      "- [TRAIN] LOSS : 0.00043292406836472865 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0002499344409443438 SCORE : 1.0\n",
      "[380/1000]\n",
      "- [TRAIN] LOSS : 0.00042983014362915937 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00024795622448436916 SCORE : 1.0\n",
      "[381/1000]\n",
      "- [TRAIN] LOSS : 0.0004267538873439965 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00024599619791842997 SCORE : 1.0\n",
      "[382/1000]\n",
      "- [TRAIN] LOSS : 0.00042370826445726887 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0002440652169752866 SCORE : 1.0\n",
      "[383/1000]\n",
      "- [TRAIN] LOSS : 0.0004206903815631651 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00024214190489146858 SCORE : 1.0\n",
      "[384/1000]\n",
      "- [TRAIN] LOSS : 0.0004176965424752173 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00024023269361350685 SCORE : 1.0\n",
      "[385/1000]\n",
      "- [TRAIN] LOSS : 0.00041473168837708526 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00023834597959648818 SCORE : 1.0\n",
      "[386/1000]\n",
      "- [TRAIN] LOSS : 0.00041178880928782746 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0002364796819165349 SCORE : 1.0\n",
      "[387/1000]\n",
      "- [TRAIN] LOSS : 0.0004088714025177372 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00023463135585188866 SCORE : 1.0\n",
      "[388/1000]\n",
      "- [TRAIN] LOSS : 0.0004059830470295209 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.000232796257478185 SCORE : 1.0\n",
      "[389/1000]\n",
      "- [TRAIN] LOSS : 0.00040311771186275617 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0002309779083589092 SCORE : 1.0\n",
      "[390/1000]\n",
      "- [TRAIN] LOSS : 0.0004002733419636368 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00022916682064533234 SCORE : 1.0\n",
      "[391/1000]\n",
      "- [TRAIN] LOSS : 0.00039746653540836024 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00022738092229701579 SCORE : 1.0\n",
      "[392/1000]\n",
      "- [TRAIN] LOSS : 0.0003946658972482611 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.000225607116590254 SCORE : 1.0\n",
      "[393/1000]\n",
      "- [TRAIN] LOSS : 0.0003919086981719981 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00022384674230124801 SCORE : 1.0\n",
      "[394/1000]\n",
      "- [TRAIN] LOSS : 0.000389158720887887 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00022210797760635614 SCORE : 1.0\n",
      "[395/1000]\n",
      "- [TRAIN] LOSS : 0.000386443842014867 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0002203868789365515 SCORE : 1.0\n",
      "[396/1000]\n",
      "- [TRAIN] LOSS : 0.0003837455992147119 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00021868156909476966 SCORE : 1.0\n",
      "[397/1000]\n",
      "- [TRAIN] LOSS : 0.00038106903634292796 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00021699840726796538 SCORE : 1.0\n",
      "[398/1000]\n",
      "- [TRAIN] LOSS : 0.0003784191301545232 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00021532236132770777 SCORE : 1.0\n",
      "[399/1000]\n",
      "- [TRAIN] LOSS : 0.000375788904623025 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00021366214787121862 SCORE : 1.0\n",
      "[400/1000]\n",
      "- [TRAIN] LOSS : 0.0003731790679416412 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00021202002244535834 SCORE : 1.0\n",
      "[401/1000]\n",
      "- [TRAIN] LOSS : 0.0003705926291230652 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00021038307750131935 SCORE : 1.0\n",
      "[402/1000]\n",
      "- [TRAIN] LOSS : 0.0003680295711900625 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00020878126088064164 SCORE : 1.0\n",
      "[403/1000]\n",
      "- [TRAIN] LOSS : 0.0003654942152530162 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.000207176199182868 SCORE : 1.0\n",
      "[404/1000]\n",
      "- [TRAIN] LOSS : 0.000362968093314622 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00020559356198646128 SCORE : 1.0\n",
      "[405/1000]\n",
      "- [TRAIN] LOSS : 0.000360465947273446 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00020403116650413722 SCORE : 1.0\n",
      "[406/1000]\n",
      "- [TRAIN] LOSS : 0.0003579858966986649 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0002024611021624878 SCORE : 1.0\n",
      "[407/1000]\n",
      "- [TRAIN] LOSS : 0.0003555250813304964 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0002009253657888621 SCORE : 1.0\n",
      "[408/1000]\n",
      "- [TRAIN] LOSS : 0.00035307795284703997 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00019937580509576946 SCORE : 1.0\n",
      "[409/1000]\n",
      "- [TRAIN] LOSS : 0.0003506662089623407 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0001978383370442316 SCORE : 1.0\n",
      "[410/1000]\n",
      "- [TRAIN] LOSS : 0.0003482792736677867 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00019631313625723124 SCORE : 1.0\n",
      "[411/1000]\n",
      "- [TRAIN] LOSS : 0.00034591564973298874 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00019480529590509832 SCORE : 1.0\n",
      "[412/1000]\n",
      "- [TRAIN] LOSS : 0.0003435674378932971 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00019331528164912015 SCORE : 1.0\n",
      "[413/1000]\n",
      "- [TRAIN] LOSS : 0.00034124035058387864 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0001918415946420282 SCORE : 1.0\n",
      "[414/1000]\n",
      "- [TRAIN] LOSS : 0.0003389331185543496 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00019037877791561186 SCORE : 1.0\n",
      "[415/1000]\n",
      "- [TRAIN] LOSS : 0.0003366505390860968 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0001889383711386472 SCORE : 1.0\n",
      "[416/1000]\n",
      "- [TRAIN] LOSS : 0.0003343768573055665 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00018750173330772668 SCORE : 1.0\n",
      "[417/1000]\n",
      "- [TRAIN] LOSS : 0.00033212970447493717 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0001860782504081726 SCORE : 1.0\n",
      "[418/1000]\n",
      "- [TRAIN] LOSS : 0.0003298900062671035 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0001846703962655738 SCORE : 1.0\n",
      "[419/1000]\n",
      "- [TRAIN] LOSS : 0.0003276780795810434 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00018328933219891042 SCORE : 1.0\n",
      "[420/1000]\n",
      "- [TRAIN] LOSS : 0.00032548009282133233 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00018190564878750592 SCORE : 1.0\n",
      "[421/1000]\n",
      "- [TRAIN] LOSS : 0.00032329484707184345 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00018054932297673076 SCORE : 1.0\n",
      "[422/1000]\n",
      "- [TRAIN] LOSS : 0.00032113537276422396 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00017920159734785557 SCORE : 1.0\n",
      "[423/1000]\n",
      "- [TRAIN] LOSS : 0.0003189874534857356 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00017786052194423974 SCORE : 1.0\n",
      "[424/1000]\n",
      "- [TRAIN] LOSS : 0.0003168623346330908 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.000176523913978599 SCORE : 1.0\n",
      "[425/1000]\n",
      "- [TRAIN] LOSS : 0.0003147486931993626 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00017521153495181352 SCORE : 1.0\n",
      "[426/1000]\n",
      "- [TRAIN] LOSS : 0.0003126482042716816 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00017391235451214015 SCORE : 1.0\n",
      "[427/1000]\n",
      "- [TRAIN] LOSS : 0.00031057234122676565 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00017261649190913886 SCORE : 1.0\n",
      "[428/1000]\n",
      "- [TRAIN] LOSS : 0.00030850931216264144 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0001713467063382268 SCORE : 1.0\n",
      "[429/1000]\n",
      "- [TRAIN] LOSS : 0.00030646211639072537 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00017008019494824111 SCORE : 1.0\n",
      "[430/1000]\n",
      "- [TRAIN] LOSS : 0.00030443215251175896 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00016881265037227422 SCORE : 1.0\n",
      "[431/1000]\n",
      "- [TRAIN] LOSS : 0.00030241533952196024 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00016757159028202295 SCORE : 1.0\n",
      "[432/1000]\n",
      "- [TRAIN] LOSS : 0.0003004162087260435 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00016633918858133256 SCORE : 1.0\n",
      "[433/1000]\n",
      "- [TRAIN] LOSS : 0.0002984362921173063 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0001651212078286335 SCORE : 1.0\n",
      "[434/1000]\n",
      "- [TRAIN] LOSS : 0.00029646706793250307 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00016391277313232422 SCORE : 1.0\n",
      "[435/1000]\n",
      "- [TRAIN] LOSS : 0.000294514375531839 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00016270547348540276 SCORE : 1.0\n",
      "[436/1000]\n",
      "- [TRAIN] LOSS : 0.00029257733209912357 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00016151624731719494 SCORE : 1.0\n",
      "[437/1000]\n",
      "- [TRAIN] LOSS : 0.0002906523554378913 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00016034269356168807 SCORE : 1.0\n",
      "[438/1000]\n",
      "- [TRAIN] LOSS : 0.0002887423979700543 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0001591638574609533 SCORE : 1.0\n",
      "[439/1000]\n",
      "- [TRAIN] LOSS : 0.0002868456685973797 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00015801149129401892 SCORE : 1.0\n",
      "[440/1000]\n",
      "- [TRAIN] LOSS : 0.0002849746156749057 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00015685999824199826 SCORE : 1.0\n",
      "[441/1000]\n",
      "- [TRAIN] LOSS : 0.000283104382106103 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00015571802214253694 SCORE : 1.0\n",
      "[442/1000]\n",
      "- [TRAIN] LOSS : 0.00028125549336740124 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00015458739653695375 SCORE : 1.0\n",
      "[443/1000]\n",
      "- [TRAIN] LOSS : 0.00027942171194202575 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00015347263251896948 SCORE : 1.0\n",
      "[444/1000]\n",
      "- [TRAIN] LOSS : 0.00027759713379459246 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00015235005412250757 SCORE : 1.0\n",
      "[445/1000]\n",
      "- [TRAIN] LOSS : 0.00027579286203642067 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00015125809295568615 SCORE : 1.0\n",
      "[446/1000]\n",
      "- [TRAIN] LOSS : 0.00027399640101874765 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00015016675752121955 SCORE : 1.0\n",
      "[447/1000]\n",
      "- [TRAIN] LOSS : 0.00027222261552297924 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00014908255252521485 SCORE : 1.0\n",
      "[448/1000]\n",
      "- [TRAIN] LOSS : 0.00027044863600167446 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00014800969802308828 SCORE : 1.0\n",
      "[449/1000]\n",
      "- [TRAIN] LOSS : 0.0002686951730639622 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00014693744014948606 SCORE : 1.0\n",
      "[450/1000]\n",
      "- [TRAIN] LOSS : 0.00026695465809704427 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0001458740298403427 SCORE : 1.0\n",
      "[451/1000]\n",
      "- [TRAIN] LOSS : 0.0002652268598871564 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00014482811093330383 SCORE : 1.0\n",
      "[452/1000]\n",
      "- [TRAIN] LOSS : 0.00026351138836212666 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00014379320782609284 SCORE : 1.0\n",
      "[453/1000]\n",
      "- [TRAIN] LOSS : 0.0002618071517240929 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00014276108413469046 SCORE : 1.0\n",
      "[454/1000]\n",
      "- [TRAIN] LOSS : 0.0002601177560184927 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00014173761883284897 SCORE : 1.0\n",
      "[455/1000]\n",
      "- [TRAIN] LOSS : 0.00025844836394147325 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00014071865007281303 SCORE : 1.0\n",
      "[456/1000]\n",
      "- [TRAIN] LOSS : 0.0002567818935656558 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00013972150918561965 SCORE : 1.0\n",
      "[457/1000]\n",
      "- [TRAIN] LOSS : 0.000255131913743551 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00013872211275156587 SCORE : 1.0\n",
      "[458/1000]\n",
      "- [TRAIN] LOSS : 0.0002534941898678274 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00013772548118140548 SCORE : 1.0\n",
      "[459/1000]\n",
      "- [TRAIN] LOSS : 0.0002518661126992407 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0001367497316095978 SCORE : 1.0\n",
      "[460/1000]\n",
      "- [TRAIN] LOSS : 0.00025025228791896044 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00013577031495515257 SCORE : 1.0\n",
      "[461/1000]\n",
      "- [TRAIN] LOSS : 0.0002486454242090177 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0001348118094028905 SCORE : 1.0\n",
      "[462/1000]\n",
      "- [TRAIN] LOSS : 0.0002470551808073651 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00013385347847361118 SCORE : 1.0\n",
      "[463/1000]\n",
      "- [TRAIN] LOSS : 0.00024548126667569805 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00013289708294905722 SCORE : 1.0\n",
      "[464/1000]\n",
      "- [TRAIN] LOSS : 0.00024391403551109962 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00013195148494560272 SCORE : 1.0\n",
      "[465/1000]\n",
      "- [TRAIN] LOSS : 0.00024235909828954996 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00013102267985232174 SCORE : 1.0\n",
      "[466/1000]\n",
      "- [TRAIN] LOSS : 0.00024081116579408344 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0001301002048421651 SCORE : 1.0\n",
      "[467/1000]\n",
      "- [TRAIN] LOSS : 0.0002392780346175035 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0001291710213990882 SCORE : 1.0\n",
      "[468/1000]\n",
      "- [TRAIN] LOSS : 0.00023775875443890173 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0001282629236811772 SCORE : 1.0\n",
      "[469/1000]\n",
      "- [TRAIN] LOSS : 0.00023624580515186407 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00012735449126921594 SCORE : 1.0\n",
      "[470/1000]\n",
      "- [TRAIN] LOSS : 0.00023474616318708286 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00012646496179513633 SCORE : 1.0\n",
      "[471/1000]\n",
      "- [TRAIN] LOSS : 0.00023325662025147013 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00012557282752823085 SCORE : 1.0\n",
      "[472/1000]\n",
      "- [TRAIN] LOSS : 0.00023178145865030173 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00012468041677493602 SCORE : 1.0\n",
      "[473/1000]\n",
      "- [TRAIN] LOSS : 0.0002303176532020896 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00012380459520500153 SCORE : 1.0\n",
      "[474/1000]\n",
      "- [TRAIN] LOSS : 0.00022885735638232695 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00012293666077312082 SCORE : 1.0\n",
      "[475/1000]\n",
      "- [TRAIN] LOSS : 0.00022741753370307075 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00012207691906951368 SCORE : 1.0\n",
      "[476/1000]\n",
      "- [TRAIN] LOSS : 0.00022597713622316305 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00012121653708163649 SCORE : 1.0\n",
      "[477/1000]\n",
      "- [TRAIN] LOSS : 0.00022455805002310727 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.000120370568765793 SCORE : 1.0\n",
      "[478/1000]\n",
      "- [TRAIN] LOSS : 0.00022314092105564973 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00011952612840104848 SCORE : 1.0\n",
      "[479/1000]\n",
      "- [TRAIN] LOSS : 0.00022173460133166777 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00011869388254126534 SCORE : 1.0\n",
      "[480/1000]\n",
      "- [TRAIN] LOSS : 0.00022034518972052157 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00011785642709583044 SCORE : 1.0\n",
      "[481/1000]\n",
      "- [TRAIN] LOSS : 0.00021895837320092446 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00011703544441843405 SCORE : 1.0\n",
      "[482/1000]\n",
      "- [TRAIN] LOSS : 0.00021758230731292214 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0001162220214609988 SCORE : 1.0\n",
      "[483/1000]\n",
      "- [TRAIN] LOSS : 0.00021622408530674875 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00011541432468220592 SCORE : 1.0\n",
      "[484/1000]\n",
      "- [TRAIN] LOSS : 0.00021487080084625632 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00011461431859061122 SCORE : 1.0\n",
      "[485/1000]\n",
      "- [TRAIN] LOSS : 0.00021352415448442721 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00011381149670341983 SCORE : 1.0\n",
      "[486/1000]\n",
      "- [TRAIN] LOSS : 0.00021219020022221634 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00011302889470243827 SCORE : 1.0\n",
      "[487/1000]\n",
      "- [TRAIN] LOSS : 0.00021086588296586543 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00011223694309592247 SCORE : 1.0\n",
      "[488/1000]\n",
      "- [TRAIN] LOSS : 0.00020955016629563438 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00011145677854074165 SCORE : 1.0\n",
      "[489/1000]\n",
      "- [TRAIN] LOSS : 0.00020823769591515884 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00011068835010519251 SCORE : 1.0\n",
      "[490/1000]\n",
      "- [TRAIN] LOSS : 0.00020694499875793958 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0001099230139516294 SCORE : 1.0\n",
      "[491/1000]\n",
      "- [TRAIN] LOSS : 0.0002056582658648646 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.0001091674785129726 SCORE : 1.0\n",
      "[492/1000]\n",
      "- [TRAIN] LOSS : 0.00020437651174789708 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00010840447066584602 SCORE : 1.0\n",
      "[493/1000]\n",
      "- [TRAIN] LOSS : 0.00020310638016477847 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00010765932529466227 SCORE : 1.0\n",
      "[494/1000]\n",
      "- [TRAIN] LOSS : 0.00020184769527986646 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00010691963689168915 SCORE : 1.0\n",
      "[495/1000]\n",
      "- [TRAIN] LOSS : 0.00020059835595829 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00010618283704388887 SCORE : 1.0\n",
      "[496/1000]\n",
      "- [TRAIN] LOSS : 0.00019935526425898488 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00010544488031882793 SCORE : 1.0\n",
      "[497/1000]\n",
      "- [TRAIN] LOSS : 0.00019811769743682817 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00010472285066498443 SCORE : 1.0\n",
      "[498/1000]\n",
      "- [TRAIN] LOSS : 0.00019689757997790971 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00010399949678685516 SCORE : 1.0\n",
      "[499/1000]\n",
      "- [TRAIN] LOSS : 0.00019567732346735688 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00010328340431442484 SCORE : 1.0\n",
      "[500/1000]\n",
      "- [TRAIN] LOSS : 0.00019446689596710107 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00010256923269480467 SCORE : 1.0\n",
      "[501/1000]\n",
      "- [TRAIN] LOSS : 0.00019327087971355973 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00010186187137151137 SCORE : 1.0\n",
      "[502/1000]\n",
      "- [TRAIN] LOSS : 0.000192078341367758 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00010115726763615385 SCORE : 1.0\n",
      "[503/1000]\n",
      "- [TRAIN] LOSS : 0.00019090630222409446 SCORE : 1.0\n",
      "- [VALID] LOSS : 0.00010045266390079632 SCORE : 1.0\n",
      "[504/1000]\n",
      "- [TRAIN] LOSS : 0.00018973639170225296 SCORE : 1.0\n",
      "- [VALID] LOSS : 9.975361172109842e-05 SCORE : 1.0\n",
      "[505/1000]\n",
      "- [TRAIN] LOSS : 0.0001885748432768095 SCORE : 1.0\n",
      "- [VALID] LOSS : 9.906825289363042e-05 SCORE : 1.0\n",
      "[506/1000]\n",
      "- [TRAIN] LOSS : 0.0001874216302692528 SCORE : 1.0\n",
      "- [VALID] LOSS : 9.837939433054999e-05 SCORE : 1.0\n",
      "[507/1000]\n",
      "- [TRAIN] LOSS : 0.00018627351851642338 SCORE : 1.0\n",
      "- [VALID] LOSS : 9.770873293746263e-05 SCORE : 1.0\n",
      "[508/1000]\n",
      "- [TRAIN] LOSS : 0.00018513506478888707 SCORE : 1.0\n",
      "- [VALID] LOSS : 9.70391629380174e-05 SCORE : 1.0\n",
      "[509/1000]\n",
      "- [TRAIN] LOSS : 0.00018400523428378315 SCORE : 1.0\n",
      "- [VALID] LOSS : 9.636244067223743e-05 SCORE : 1.0\n",
      "[510/1000]\n",
      "- [TRAIN] LOSS : 0.00018288079405061176 SCORE : 1.0\n",
      "- [VALID] LOSS : 9.56998483161442e-05 SCORE : 1.0\n",
      "[511/1000]\n",
      "- [TRAIN] LOSS : 0.00018176978806473521 SCORE : 1.0\n",
      "- [VALID] LOSS : 9.505601337878034e-05 SCORE : 1.0\n",
      "[512/1000]\n",
      "- [TRAIN] LOSS : 0.00018065914789783873 SCORE : 1.0\n",
      "- [VALID] LOSS : 9.440739086130634e-05 SCORE : 1.0\n",
      "[513/1000]\n",
      "- [TRAIN] LOSS : 0.0001795641300203796 SCORE : 1.0\n",
      "- [VALID] LOSS : 9.376258094562218e-05 SCORE : 1.0\n",
      "[514/1000]\n",
      "- [TRAIN] LOSS : 0.00017847459861918146 SCORE : 1.0\n",
      "- [VALID] LOSS : 9.312406473327428e-05 SCORE : 1.0\n",
      "[515/1000]\n",
      "- [TRAIN] LOSS : 0.0001773878753334025 SCORE : 1.0\n",
      "- [VALID] LOSS : 9.248759306501597e-05 SCORE : 1.0\n",
      "[516/1000]\n",
      "- [TRAIN] LOSS : 0.0001763148474209528 SCORE : 1.0\n",
      "- [VALID] LOSS : 9.185724047711119e-05 SCORE : 1.0\n",
      "[517/1000]\n",
      "- [TRAIN] LOSS : 0.0001752484479058896 SCORE : 1.0\n",
      "- [VALID] LOSS : 9.123315248871222e-05 SCORE : 1.0\n",
      "[518/1000]\n",
      "- [TRAIN] LOSS : 0.0001741810637112293 SCORE : 1.0\n",
      "- [VALID] LOSS : 9.061556920642033e-05 SCORE : 1.0\n",
      "[519/1000]\n",
      "- [TRAIN] LOSS : 0.00017312785671998022 SCORE : 1.0\n",
      "- [VALID] LOSS : 8.999999408842996e-05 SCORE : 1.0\n",
      "[520/1000]\n",
      "- [TRAIN] LOSS : 0.0001720776468169384 SCORE : 1.0\n",
      "- [VALID] LOSS : 8.939086546888575e-05 SCORE : 1.0\n",
      "[521/1000]\n",
      "- [TRAIN] LOSS : 0.00017103524805861525 SCORE : 1.0\n",
      "- [VALID] LOSS : 8.879658707883209e-05 SCORE : 1.0\n",
      "[522/1000]\n",
      "- [TRAIN] LOSS : 0.0001700054645981355 SCORE : 1.0\n",
      "- [VALID] LOSS : 8.819163485895842e-05 SCORE : 1.0\n",
      "[523/1000]\n",
      "- [TRAIN] LOSS : 0.00016897514231257245 SCORE : 1.0\n",
      "- [VALID] LOSS : 8.7593165517319e-05 SCORE : 1.0\n",
      "[524/1000]\n",
      "- [TRAIN] LOSS : 0.00016796164972119086 SCORE : 1.0\n",
      "- [VALID] LOSS : 8.699485624674708e-05 SCORE : 1.0\n",
      "[525/1000]\n",
      "- [TRAIN] LOSS : 0.00016694651336971825 SCORE : 1.0\n",
      "- [VALID] LOSS : 8.641347812954336e-05 SCORE : 1.0\n",
      "[526/1000]\n",
      "- [TRAIN] LOSS : 0.00016593848178874597 SCORE : 1.0\n",
      "- [VALID] LOSS : 8.583005546825007e-05 SCORE : 1.0\n",
      "[527/1000]\n",
      "- [TRAIN] LOSS : 0.000164936701063804 SCORE : 1.0\n",
      "- [VALID] LOSS : 8.524885924998671e-05 SCORE : 1.0\n",
      "[528/1000]\n",
      "- [TRAIN] LOSS : 0.00016394468810984917 SCORE : 1.0\n",
      "- [VALID] LOSS : 8.468252781312913e-05 SCORE : 1.0\n",
      "[529/1000]\n",
      "- [TRAIN] LOSS : 0.0001629637473443937 SCORE : 1.0\n",
      "- [VALID] LOSS : 8.412256283918396e-05 SCORE : 1.0\n",
      "[530/1000]\n",
      "- [TRAIN] LOSS : 0.00016198140696764717 SCORE : 1.0\n",
      "- [VALID] LOSS : 8.355864702025428e-05 SCORE : 1.0\n",
      "[531/1000]\n",
      "- [TRAIN] LOSS : 0.000161013621537778 SCORE : 1.0\n",
      "- [VALID] LOSS : 8.299035107484087e-05 SCORE : 1.0\n",
      "[532/1000]\n",
      "- [TRAIN] LOSS : 0.0001600432303045333 SCORE : 1.0\n",
      "- [VALID] LOSS : 8.243275078712031e-05 SCORE : 1.0\n",
      "[533/1000]\n",
      "- [TRAIN] LOSS : 0.00015908606534746164 SCORE : 1.0\n",
      "- [VALID] LOSS : 8.188164792954922e-05 SCORE : 1.0\n",
      "[534/1000]\n",
      "- [TRAIN] LOSS : 0.00015812697731437057 SCORE : 1.0\n",
      "- [VALID] LOSS : 8.13324804767035e-05 SCORE : 1.0\n",
      "[535/1000]\n",
      "- [TRAIN] LOSS : 0.00015718637466003807 SCORE : 1.0\n",
      "- [VALID] LOSS : 8.078980317804962e-05 SCORE : 1.0\n",
      "[536/1000]\n",
      "- [TRAIN] LOSS : 0.0001562466139956895 SCORE : 1.0\n",
      "- [VALID] LOSS : 8.024925773497671e-05 SCORE : 1.0\n",
      "[537/1000]\n",
      "- [TRAIN] LOSS : 0.00015530885644289406 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.971499144332483e-05 SCORE : 1.0\n",
      "[538/1000]\n",
      "- [TRAIN] LOSS : 0.0001543802239514965 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.918272604001686e-05 SCORE : 1.0\n",
      "[539/1000]\n",
      "- [TRAIN] LOSS : 0.0001534626505114526 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.865908992243931e-05 SCORE : 1.0\n",
      "[540/1000]\n",
      "- [TRAIN] LOSS : 0.00015254944042276798 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.81310154707171e-05 SCORE : 1.0\n",
      "[541/1000]\n",
      "- [TRAIN] LOSS : 0.00015163611169555224 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.761344750178978e-05 SCORE : 1.0\n",
      "[542/1000]\n",
      "- [TRAIN] LOSS : 0.00015073563291581295 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.709373312536627e-05 SCORE : 1.0\n",
      "[543/1000]\n",
      "- [TRAIN] LOSS : 0.00014983480347533865 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.658029062440619e-05 SCORE : 1.0\n",
      "[544/1000]\n",
      "- [TRAIN] LOSS : 0.00014894249276646102 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.60730035835877e-05 SCORE : 1.0\n",
      "[545/1000]\n",
      "- [TRAIN] LOSS : 0.00014806238848703087 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.556776836281642e-05 SCORE : 1.0\n",
      "[546/1000]\n",
      "- [TRAIN] LOSS : 0.00014718412745019628 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.506865949835628e-05 SCORE : 1.0\n",
      "[547/1000]\n",
      "- [TRAIN] LOSS : 0.00014630575889087695 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.457163883373141e-05 SCORE : 1.0\n",
      "[548/1000]\n",
      "- [TRAIN] LOSS : 0.00014543739174162815 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.407648809021339e-05 SCORE : 1.0\n",
      "[549/1000]\n",
      "- [TRAIN] LOSS : 0.0001445764594084014 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.357259892160073e-05 SCORE : 1.0\n",
      "[550/1000]\n",
      "- [TRAIN] LOSS : 0.00014371874547375936 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.307530904654413e-05 SCORE : 1.0\n",
      "[551/1000]\n",
      "- [TRAIN] LOSS : 0.0001428747645048942 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.258015830302611e-05 SCORE : 1.0\n",
      "[552/1000]\n",
      "- [TRAIN] LOSS : 0.00014203079990693368 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.209396426333115e-05 SCORE : 1.0\n",
      "[553/1000]\n",
      "- [TRAIN] LOSS : 0.00014119827776287112 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.160770474001765e-05 SCORE : 1.0\n",
      "[554/1000]\n",
      "- [TRAIN] LOSS : 0.0001403730406713698 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.112971070455387e-05 SCORE : 1.0\n",
      "[555/1000]\n",
      "- [TRAIN] LOSS : 0.00013954302408415565 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.065793761285022e-05 SCORE : 1.0\n",
      "[556/1000]\n",
      "- [TRAIN] LOSS : 0.00013872778213731686 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.017129973974079e-05 SCORE : 1.0\n",
      "[557/1000]\n",
      "- [TRAIN] LOSS : 0.00013790849738547372 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.971458060434088e-05 SCORE : 1.0\n",
      "[558/1000]\n",
      "- [TRAIN] LOSS : 0.0001371039242157066 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.924539775354788e-05 SCORE : 1.0\n",
      "[559/1000]\n",
      "- [TRAIN] LOSS : 0.00013629944765448777 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.878942804178223e-05 SCORE : 1.0\n",
      "[560/1000]\n",
      "- [TRAIN] LOSS : 0.00013550262499645923 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.833630322944373e-05 SCORE : 1.0\n",
      "[561/1000]\n",
      "- [TRAIN] LOSS : 0.00013471204996070205 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.787333404645324e-05 SCORE : 1.0\n",
      "[562/1000]\n",
      "- [TRAIN] LOSS : 0.00013392273548460152 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.743242556694895e-05 SCORE : 1.0\n",
      "[563/1000]\n",
      "- [TRAIN] LOSS : 0.00013314273989332529 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.698830839013681e-05 SCORE : 1.0\n",
      "[564/1000]\n",
      "- [TRAIN] LOSS : 0.00013236296298499737 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.654083699686453e-05 SCORE : 1.0\n",
      "[565/1000]\n",
      "- [TRAIN] LOSS : 0.00013158872247408403 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.61072917864658e-05 SCORE : 1.0\n",
      "[566/1000]\n",
      "- [TRAIN] LOSS : 0.00013081909027176961 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.566204683622345e-05 SCORE : 1.0\n",
      "[567/1000]\n",
      "- [TRAIN] LOSS : 0.00013005956599146075 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.524348282255232e-05 SCORE : 1.0\n",
      "[568/1000]\n",
      "- [TRAIN] LOSS : 0.00012930338986431403 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.481338641606271e-05 SCORE : 1.0\n",
      "[569/1000]\n",
      "- [TRAIN] LOSS : 0.000128550846865336 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.438460695790127e-05 SCORE : 1.0\n",
      "[570/1000]\n",
      "- [TRAIN] LOSS : 0.00012780088258700239 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.396563549060374e-05 SCORE : 1.0\n",
      "[571/1000]\n",
      "- [TRAIN] LOSS : 0.00012705646683267938 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.3556399254594e-05 SCORE : 1.0\n",
      "[572/1000]\n",
      "- [TRAIN] LOSS : 0.00012632135359227605 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.313143967418e-05 SCORE : 1.0\n",
      "[573/1000]\n",
      "- [TRAIN] LOSS : 0.0001255873745928208 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.272065365919843e-05 SCORE : 1.0\n",
      "[574/1000]\n",
      "- [TRAIN] LOSS : 0.00012485361569108337 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.23070154688321e-05 SCORE : 1.0\n",
      "[575/1000]\n",
      "- [TRAIN] LOSS : 0.00012413310570183158 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.190333078848198e-05 SCORE : 1.0\n",
      "[576/1000]\n",
      "- [TRAIN] LOSS : 0.0001234096097404189 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.149668479338288e-05 SCORE : 1.0\n",
      "[577/1000]\n",
      "- [TRAIN] LOSS : 0.00012269989383639768 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.109361856942996e-05 SCORE : 1.0\n",
      "[578/1000]\n",
      "- [TRAIN] LOSS : 0.00012198912372696213 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.070251765777357e-05 SCORE : 1.0\n",
      "[579/1000]\n",
      "- [TRAIN] LOSS : 0.00012127519787302137 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.030431904946454e-05 SCORE : 1.0\n",
      "[580/1000]\n",
      "- [TRAIN] LOSS : 0.00012057596662392218 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.9920246712863445e-05 SCORE : 1.0\n",
      "[581/1000]\n",
      "- [TRAIN] LOSS : 0.00011988031413541951 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.952058927505277e-05 SCORE : 1.0\n",
      "[582/1000]\n",
      "- [TRAIN] LOSS : 0.00011919020976670759 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.913934001000598e-05 SCORE : 1.0\n",
      "[583/1000]\n",
      "- [TRAIN] LOSS : 0.0001184989939954701 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.875105853192508e-05 SCORE : 1.0\n",
      "[584/1000]\n",
      "- [TRAIN] LOSS : 0.00011781755509016673 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.836842319695279e-05 SCORE : 1.0\n",
      "[585/1000]\n",
      "- [TRAIN] LOSS : 0.00011713553350192442 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.800073267892003e-05 SCORE : 1.0\n",
      "[586/1000]\n",
      "- [TRAIN] LOSS : 0.00011646140248760478 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.761054126196541e-05 SCORE : 1.0\n",
      "[587/1000]\n",
      "- [TRAIN] LOSS : 0.00011579197376300322 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.7238852605223656e-05 SCORE : 1.0\n",
      "[588/1000]\n",
      "- [TRAIN] LOSS : 0.00011512831770232879 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.686805161531083e-05 SCORE : 1.0\n",
      "[589/1000]\n",
      "- [TRAIN] LOSS : 0.00011446088117534398 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.6493478041375056e-05 SCORE : 1.0\n",
      "[590/1000]\n",
      "- [TRAIN] LOSS : 0.00011380966619375006 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.612744644167833e-05 SCORE : 1.0\n",
      "[591/1000]\n",
      "- [TRAIN] LOSS : 0.00011315531972084298 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.5757638619979843e-05 SCORE : 1.0\n",
      "[592/1000]\n",
      "- [TRAIN] LOSS : 0.00011250726957870129 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.539717312785797e-05 SCORE : 1.0\n",
      "[593/1000]\n",
      "- [TRAIN] LOSS : 0.00011186283861914287 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.5041746236383915e-05 SCORE : 1.0\n",
      "[594/1000]\n",
      "- [TRAIN] LOSS : 0.00011122127762064338 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.468301969813183e-05 SCORE : 1.0\n",
      "[595/1000]\n",
      "- [TRAIN] LOSS : 0.00011058363250210985 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.432561010820791e-05 SCORE : 1.0\n",
      "[596/1000]\n",
      "- [TRAIN] LOSS : 0.00010995253230956021 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.3978281357558444e-05 SCORE : 1.0\n",
      "[597/1000]\n",
      "- [TRAIN] LOSS : 0.0001093200426112162 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.3623651183443144e-05 SCORE : 1.0\n",
      "[598/1000]\n",
      "- [TRAIN] LOSS : 0.0001086984365328034 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.327857070369646e-05 SCORE : 1.0\n",
      "[599/1000]\n",
      "- [TRAIN] LOSS : 0.00010807560425342267 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.2934428822482005e-05 SCORE : 1.0\n",
      "[600/1000]\n",
      "- [TRAIN] LOSS : 0.00010745864710770547 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.25997020304203e-05 SCORE : 1.0\n",
      "[601/1000]\n",
      "- [TRAIN] LOSS : 0.0001068436166759865 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.2257466450100765e-05 SCORE : 1.0\n",
      "[602/1000]\n",
      "- [TRAIN] LOSS : 0.00010623534823632023 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.191702439333312e-05 SCORE : 1.0\n",
      "[603/1000]\n",
      "- [TRAIN] LOSS : 0.0001056328057731864 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.158225758350454e-05 SCORE : 1.0\n",
      "[604/1000]\n",
      "- [TRAIN] LOSS : 0.00010503239435719378 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.125048846821301e-05 SCORE : 1.0\n",
      "[605/1000]\n",
      "- [TRAIN] LOSS : 0.00010443728650797211 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.0920654757646844e-05 SCORE : 1.0\n",
      "[606/1000]\n",
      "- [TRAIN] LOSS : 0.00010384699635324068 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.0591879698913544e-05 SCORE : 1.0\n",
      "[607/1000]\n",
      "- [TRAIN] LOSS : 0.00010325693902915291 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.0261940486961976e-05 SCORE : 1.0\n",
      "[608/1000]\n",
      "- [TRAIN] LOSS : 0.00010266981583602804 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.994327173335478e-05 SCORE : 1.0\n",
      "[609/1000]\n",
      "- [TRAIN] LOSS : 0.00010208446353014249 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.962519960827194e-05 SCORE : 1.0\n",
      "[610/1000]\n",
      "- [TRAIN] LOSS : 0.00010150293170833417 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.930346767650917e-05 SCORE : 1.0\n",
      "[611/1000]\n",
      "- [TRAIN] LOSS : 0.000100931960433728 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.898675251752138e-05 SCORE : 1.0\n",
      "[612/1000]\n",
      "- [TRAIN] LOSS : 0.00010035706448737376 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.867496318183839e-05 SCORE : 1.0\n",
      "[613/1000]\n",
      "- [TRAIN] LOSS : 9.97882957057704e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.8359710490331054e-05 SCORE : 1.0\n",
      "[614/1000]\n",
      "- [TRAIN] LOSS : 9.922653023548062e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.804748823517002e-05 SCORE : 1.0\n",
      "[615/1000]\n",
      "- [TRAIN] LOSS : 9.86606707253183e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.773819091496989e-05 SCORE : 1.0\n",
      "[616/1000]\n",
      "- [TRAIN] LOSS : 9.810720469734709e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.7438319597858936e-05 SCORE : 1.0\n",
      "[617/1000]\n",
      "- [TRAIN] LOSS : 9.755634538224613e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.713080488727428e-05 SCORE : 1.0\n",
      "[618/1000]\n",
      "- [TRAIN] LOSS : 9.700357915992047e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.6832796215312555e-05 SCORE : 1.0\n",
      "[619/1000]\n",
      "- [TRAIN] LOSS : 9.645415957493242e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.653566065826453e-05 SCORE : 1.0\n",
      "[620/1000]\n",
      "- [TRAIN] LOSS : 9.591470643499633e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.6243734686868265e-05 SCORE : 1.0\n",
      "[621/1000]\n",
      "- [TRAIN] LOSS : 9.537012051118331e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.5944256271468475e-05 SCORE : 1.0\n",
      "[622/1000]\n",
      "- [TRAIN] LOSS : 9.48323792423859e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.5654272980755195e-05 SCORE : 1.0\n",
      "[623/1000]\n",
      "- [TRAIN] LOSS : 9.429616127615898e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.5365213736658916e-05 SCORE : 1.0\n",
      "[624/1000]\n",
      "- [TRAIN] LOSS : 9.376864656789823e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.507713674684055e-05 SCORE : 1.0\n",
      "[625/1000]\n",
      "- [TRAIN] LOSS : 9.323864823171688e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.4785734644392505e-05 SCORE : 1.0\n",
      "[626/1000]\n",
      "- [TRAIN] LOSS : 9.271283751230739e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.45037912868429e-05 SCORE : 1.0\n",
      "[627/1000]\n",
      "- [TRAIN] LOSS : 9.218854463850019e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.422276469995268e-05 SCORE : 1.0\n",
      "[628/1000]\n",
      "- [TRAIN] LOSS : 9.167115442525958e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.3934247514698654e-05 SCORE : 1.0\n",
      "[629/1000]\n",
      "- [TRAIN] LOSS : 9.116663012618019e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.3655272747855633e-05 SCORE : 1.0\n",
      "[630/1000]\n",
      "- [TRAIN] LOSS : 9.064592520897147e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.3377214751672e-05 SCORE : 1.0\n",
      "[631/1000]\n",
      "- [TRAIN] LOSS : 9.013660969180314e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.310865915613249e-05 SCORE : 1.0\n",
      "[632/1000]\n",
      "- [TRAIN] LOSS : 8.962960024897863e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.283682210370898e-05 SCORE : 1.0\n",
      "[633/1000]\n",
      "- [TRAIN] LOSS : 8.912810911472964e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.25658690801356e-05 SCORE : 1.0\n",
      "[634/1000]\n",
      "- [TRAIN] LOSS : 8.862893830357482e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.2295840103179216e-05 SCORE : 1.0\n",
      "[635/1000]\n",
      "- [TRAIN] LOSS : 8.813190510813406e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.2031027987832204e-05 SCORE : 1.0\n",
      "[636/1000]\n",
      "- [TRAIN] LOSS : 8.7639795007514e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.1762945329537615e-05 SCORE : 1.0\n",
      "[637/1000]\n",
      "- [TRAIN] LOSS : 8.714601547884134e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.150007225689478e-05 SCORE : 1.0\n",
      "[638/1000]\n",
      "- [TRAIN] LOSS : 8.665846427094139e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.123815961065702e-05 SCORE : 1.0\n",
      "[639/1000]\n",
      "- [TRAIN] LOSS : 8.617394228672815e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.098137651453726e-05 SCORE : 1.0\n",
      "[640/1000]\n",
      "- [TRAIN] LOSS : 8.569150456120649e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.0725524740992114e-05 SCORE : 1.0\n",
      "[641/1000]\n",
      "- [TRAIN] LOSS : 8.521662756619562e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.046207686769776e-05 SCORE : 1.0\n",
      "[642/1000]\n",
      "- [TRAIN] LOSS : 8.473803164734918e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.021655331598595e-05 SCORE : 1.0\n",
      "[643/1000]\n",
      "- [TRAIN] LOSS : 8.426092618820904e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.995493534603156e-05 SCORE : 1.0\n",
      "[644/1000]\n",
      "- [TRAIN] LOSS : 8.379717635559953e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.9703038055449724e-05 SCORE : 1.0\n",
      "[645/1000]\n",
      "- [TRAIN] LOSS : 8.332739050981925e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.945584103348665e-05 SCORE : 1.0\n",
      "[646/1000]\n",
      "- [TRAIN] LOSS : 8.286080719699385e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.920933886547573e-05 SCORE : 1.0\n",
      "[647/1000]\n",
      "- [TRAIN] LOSS : 8.239874983296936e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.895943518728018e-05 SCORE : 1.0\n",
      "[648/1000]\n",
      "- [TRAIN] LOSS : 8.194017926952155e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.8718939322279766e-05 SCORE : 1.0\n",
      "[649/1000]\n",
      "- [TRAIN] LOSS : 8.147868548904726e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.8479392969748005e-05 SCORE : 1.0\n",
      "[650/1000]\n",
      "- [TRAIN] LOSS : 8.103281945497858e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.823650331469253e-05 SCORE : 1.0\n",
      "[651/1000]\n",
      "- [TRAIN] LOSS : 8.057791122458487e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.799877595156431e-05 SCORE : 1.0\n",
      "[652/1000]\n",
      "- [TRAIN] LOSS : 8.012541396359059e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.7758411053800955e-05 SCORE : 1.0\n",
      "[653/1000]\n",
      "- [TRAIN] LOSS : 7.968478500212466e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.752179691218771e-05 SCORE : 1.0\n",
      "[654/1000]\n",
      "- [TRAIN] LOSS : 7.923740334566294e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.7279893149388954e-05 SCORE : 1.0\n",
      "[655/1000]\n",
      "- [TRAIN] LOSS : 7.880048603207494e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.7047324440209195e-05 SCORE : 1.0\n",
      "[656/1000]\n",
      "- [TRAIN] LOSS : 7.836151245202118e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.681975067593157e-05 SCORE : 1.0\n",
      "[657/1000]\n",
      "- [TRAIN] LOSS : 7.792634995793278e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.65885607607197e-05 SCORE : 1.0\n",
      "[658/1000]\n",
      "- [TRAIN] LOSS : 7.749814883734669e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.635801840573549e-05 SCORE : 1.0\n",
      "[659/1000]\n",
      "- [TRAIN] LOSS : 7.706761678289493e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.61324091500137e-05 SCORE : 1.0\n",
      "[660/1000]\n",
      "- [TRAIN] LOSS : 7.663747641749473e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.590325286495499e-05 SCORE : 1.0\n",
      "[661/1000]\n",
      "- [TRAIN] LOSS : 7.621031333352828e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.567893145373091e-05 SCORE : 1.0\n",
      "[662/1000]\n",
      "- [TRAIN] LOSS : 7.579530453464638e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.5455301258480176e-05 SCORE : 1.0\n",
      "[663/1000]\n",
      "- [TRAIN] LOSS : 7.53689200791996e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.523658961057663e-05 SCORE : 1.0\n",
      "[664/1000]\n",
      "- [TRAIN] LOSS : 7.495475842410492e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.501432001939975e-05 SCORE : 1.0\n",
      "[665/1000]\n",
      "- [TRAIN] LOSS : 7.45451610176436e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.478854341665283e-05 SCORE : 1.0\n",
      "[666/1000]\n",
      "- [TRAIN] LOSS : 7.412706862750283e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.458058199612424e-05 SCORE : 1.0\n",
      "[667/1000]\n",
      "- [TRAIN] LOSS : 7.372330502322357e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.4364678867859766e-05 SCORE : 1.0\n",
      "[668/1000]\n",
      "- [TRAIN] LOSS : 7.330926968683748e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.4149474231526256e-05 SCORE : 1.0\n",
      "[669/1000]\n",
      "- [TRAIN] LOSS : 7.291030639559419e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.393498991499655e-05 SCORE : 1.0\n",
      "[670/1000]\n",
      "- [TRAIN] LOSS : 7.250673621052151e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.3729833376128227e-05 SCORE : 1.0\n",
      "[671/1000]\n",
      "- [TRAIN] LOSS : 7.210975885148703e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.3516793337184936e-05 SCORE : 1.0\n",
      "[672/1000]\n",
      "- [TRAIN] LOSS : 7.170853546590984e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.330440813442692e-05 SCORE : 1.0\n",
      "[673/1000]\n",
      "- [TRAIN] LOSS : 7.131245436337647e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.309695966891013e-05 SCORE : 1.0\n",
      "[674/1000]\n",
      "- [TRAIN] LOSS : 7.091751679884813e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.288586231064983e-05 SCORE : 1.0\n",
      "[675/1000]\n",
      "- [TRAIN] LOSS : 7.052831703428335e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.268832733738236e-05 SCORE : 1.0\n",
      "[676/1000]\n",
      "- [TRAIN] LOSS : 7.013906906649936e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.248293069191277e-05 SCORE : 1.0\n",
      "[677/1000]\n",
      "- [TRAIN] LOSS : 6.975204501537114e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.228687637601979e-05 SCORE : 1.0\n",
      "[678/1000]\n",
      "- [TRAIN] LOSS : 6.936304038794737e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.207874397048727e-05 SCORE : 1.0\n",
      "[679/1000]\n",
      "- [TRAIN] LOSS : 6.899048902495351e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.1884093914413825e-05 SCORE : 1.0\n",
      "[680/1000]\n",
      "- [TRAIN] LOSS : 6.860404846520396e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.168584589730017e-05 SCORE : 1.0\n",
      "[681/1000]\n",
      "- [TRAIN] LOSS : 6.823058538429905e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.148822361254133e-05 SCORE : 1.0\n",
      "[682/1000]\n",
      "- [TRAIN] LOSS : 6.785499024570324e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.129207107122056e-05 SCORE : 1.0\n",
      "[683/1000]\n",
      "- [TRAIN] LOSS : 6.748015382779865e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.110127363470383e-05 SCORE : 1.0\n",
      "[684/1000]\n",
      "- [TRAIN] LOSS : 6.710603318222436e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.090272002737038e-05 SCORE : 1.0\n",
      "[685/1000]\n",
      "- [TRAIN] LOSS : 6.674295056857065e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.0713214073330164e-05 SCORE : 1.0\n",
      "[686/1000]\n",
      "- [TRAIN] LOSS : 6.637338881571648e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.051996463909745e-05 SCORE : 1.0\n",
      "[687/1000]\n",
      "- [TRAIN] LOSS : 6.601254921810728e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.0331479138112627e-05 SCORE : 1.0\n",
      "[688/1000]\n",
      "- [TRAIN] LOSS : 6.564580376612462e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 3.0139241061988287e-05 SCORE : 1.0\n",
      "[689/1000]\n",
      "- [TRAIN] LOSS : 6.528967110676199e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.9951692340546288e-05 SCORE : 1.0\n",
      "[690/1000]\n",
      "- [TRAIN] LOSS : 6.493223726364603e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.9768943932140246e-05 SCORE : 1.0\n",
      "[691/1000]\n",
      "- [TRAIN] LOSS : 6.457636795352705e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.9582441129605286e-05 SCORE : 1.0\n",
      "[692/1000]\n",
      "- [TRAIN] LOSS : 6.422323450452596e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.939649493782781e-05 SCORE : 1.0\n",
      "[693/1000]\n",
      "- [TRAIN] LOSS : 6.387093283895713e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.921531086030882e-05 SCORE : 1.0\n",
      "[694/1000]\n",
      "- [TRAIN] LOSS : 6.351959685465165e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.9043179893051274e-05 SCORE : 1.0\n",
      "[695/1000]\n",
      "- [TRAIN] LOSS : 6.31763433476509e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.8854559786850587e-05 SCORE : 1.0\n",
      "[696/1000]\n",
      "- [TRAIN] LOSS : 6.283331175735738e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.8675027351710014e-05 SCORE : 1.0\n",
      "[697/1000]\n",
      "- [TRAIN] LOSS : 6.248800996723326e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.850026976375375e-05 SCORE : 1.0\n",
      "[698/1000]\n",
      "- [TRAIN] LOSS : 6.214766926859738e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.832187237800099e-05 SCORE : 1.0\n",
      "[699/1000]\n",
      "- [TRAIN] LOSS : 6.181030635667007e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.814830259012524e-05 SCORE : 1.0\n",
      "[700/1000]\n",
      "- [TRAIN] LOSS : 6.14686283976577e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.797098204609938e-05 SCORE : 1.0\n",
      "[701/1000]\n",
      "- [TRAIN] LOSS : 6.113047670118653e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.780695831461344e-05 SCORE : 1.0\n",
      "[702/1000]\n",
      "- [TRAIN] LOSS : 6.0797624984034985e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.763063457678072e-05 SCORE : 1.0\n",
      "[703/1000]\n",
      "- [TRAIN] LOSS : 6.0463834617823726e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.7463422156870365e-05 SCORE : 1.0\n",
      "[704/1000]\n",
      "- [TRAIN] LOSS : 6.013690108375158e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.7292453523841687e-05 SCORE : 1.0\n",
      "[705/1000]\n",
      "- [TRAIN] LOSS : 5.9812345878324573e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.712635978241451e-05 SCORE : 1.0\n",
      "[706/1000]\n",
      "- [TRAIN] LOSS : 5.9483806782938904e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.6965328288497403e-05 SCORE : 1.0\n",
      "[707/1000]\n",
      "- [TRAIN] LOSS : 5.916120512160382e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.679227509361226e-05 SCORE : 1.0\n",
      "[708/1000]\n",
      "- [TRAIN] LOSS : 5.883470607336171e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.6628316845744848e-05 SCORE : 1.0\n",
      "[709/1000]\n",
      "- [TRAIN] LOSS : 5.851579544469132e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.6460562366992235e-05 SCORE : 1.0\n",
      "[710/1000]\n",
      "- [TRAIN] LOSS : 5.819571555952684e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.630608832987491e-05 SCORE : 1.0\n",
      "[711/1000]\n",
      "- [TRAIN] LOSS : 5.788439092510897e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.6139312467421405e-05 SCORE : 1.0\n",
      "[712/1000]\n",
      "- [TRAIN] LOSS : 5.756443958186234e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.59736661973875e-05 SCORE : 1.0\n",
      "[713/1000]\n",
      "- [TRAIN] LOSS : 5.725121647830949e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.5808671125560068e-05 SCORE : 1.0\n",
      "[714/1000]\n",
      "- [TRAIN] LOSS : 5.694187039908785e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.5652660042396747e-05 SCORE : 1.0\n",
      "[715/1000]\n",
      "- [TRAIN] LOSS : 5.663325904000279e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.5492827262496576e-05 SCORE : 1.0\n",
      "[716/1000]\n",
      "- [TRAIN] LOSS : 5.6328002806872566e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.5337683837278746e-05 SCORE : 1.0\n",
      "[717/1000]\n",
      "- [TRAIN] LOSS : 5.6022712215053616e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.518294786568731e-05 SCORE : 1.0\n",
      "[718/1000]\n",
      "- [TRAIN] LOSS : 5.571755016515251e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.502887582522817e-05 SCORE : 1.0\n",
      "[719/1000]\n",
      "- [TRAIN] LOSS : 5.541703911957383e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.4879820557544008e-05 SCORE : 1.0\n",
      "[720/1000]\n",
      "- [TRAIN] LOSS : 5.511587096407311e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.4718518034205772e-05 SCORE : 1.0\n",
      "[721/1000]\n",
      "- [TRAIN] LOSS : 5.4818285005037775e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.457038681313861e-05 SCORE : 1.0\n",
      "[722/1000]\n",
      "- [TRAIN] LOSS : 5.451864621540558e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.4418373868684284e-05 SCORE : 1.0\n",
      "[723/1000]\n",
      "- [TRAIN] LOSS : 5.422280072606453e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.426671198918484e-05 SCORE : 1.0\n",
      "[724/1000]\n",
      "- [TRAIN] LOSS : 5.393207554031202e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.4123908588080667e-05 SCORE : 1.0\n",
      "[725/1000]\n",
      "- [TRAIN] LOSS : 5.363987035404231e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.3964474166859873e-05 SCORE : 1.0\n",
      "[726/1000]\n",
      "- [TRAIN] LOSS : 5.334830277408603e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.382672028033994e-05 SCORE : 1.0\n",
      "[727/1000]\n",
      "- [TRAIN] LOSS : 5.3059298099671854e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.3676559067098424e-05 SCORE : 1.0\n",
      "[728/1000]\n",
      "- [TRAIN] LOSS : 5.277619043732152e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.3531070837634616e-05 SCORE : 1.0\n",
      "[729/1000]\n",
      "- [TRAIN] LOSS : 5.2486459480860503e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.338170634175185e-05 SCORE : 1.0\n",
      "[730/1000]\n",
      "- [TRAIN] LOSS : 5.2202016225540625e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.3241242161020637e-05 SCORE : 1.0\n",
      "[731/1000]\n",
      "- [TRAIN] LOSS : 5.192282166414467e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.310118179593701e-05 SCORE : 1.0\n",
      "[732/1000]\n",
      "- [TRAIN] LOSS : 5.1643702944501354e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.2961570721236058e-05 SCORE : 1.0\n",
      "[733/1000]\n",
      "- [TRAIN] LOSS : 5.136208730820929e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.2818161596660502e-05 SCORE : 1.0\n",
      "[734/1000]\n",
      "- [TRAIN] LOSS : 5.1083888138236944e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.2675167201668955e-05 SCORE : 1.0\n",
      "[735/1000]\n",
      "- [TRAIN] LOSS : 5.081094913192727e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.253680031572003e-05 SCORE : 1.0\n",
      "[736/1000]\n",
      "- [TRAIN] LOSS : 5.053470628505844e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.240310459455941e-05 SCORE : 1.0\n",
      "[737/1000]\n",
      "- [TRAIN] LOSS : 5.0265269187042984e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.2265594452619553e-05 SCORE : 1.0\n",
      "[738/1000]\n",
      "- [TRAIN] LOSS : 4.9993932760925316e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.2128519049147144e-05 SCORE : 1.0\n",
      "[739/1000]\n",
      "- [TRAIN] LOSS : 4.972472627034424e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.1996112991473638e-05 SCORE : 1.0\n",
      "[740/1000]\n",
      "- [TRAIN] LOSS : 4.9454934469395084e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.1864165319129825e-05 SCORE : 1.0\n",
      "[741/1000]\n",
      "- [TRAIN] LOSS : 4.918721727638816e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.1724077669205144e-05 SCORE : 1.0\n",
      "[742/1000]\n",
      "- [TRAIN] LOSS : 4.892424031923939e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.1592952180071734e-05 SCORE : 1.0\n",
      "[743/1000]\n",
      "- [TRAIN] LOSS : 4.866271481457968e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.1457994080265053e-05 SCORE : 1.0\n",
      "[744/1000]\n",
      "- [TRAIN] LOSS : 4.840002576303151e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.1327699869289063e-05 SCORE : 1.0\n",
      "[745/1000]\n",
      "- [TRAIN] LOSS : 4.813676873204208e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.120207136613317e-05 SCORE : 1.0\n",
      "[746/1000]\n",
      "- [TRAIN] LOSS : 4.787887251546231e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.1068319256301038e-05 SCORE : 1.0\n",
      "[747/1000]\n",
      "- [TRAIN] LOSS : 4.761897369260421e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.093922194035258e-05 SCORE : 1.0\n",
      "[748/1000]\n",
      "- [TRAIN] LOSS : 4.73637293099374e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.0810510250157677e-05 SCORE : 1.0\n",
      "[749/1000]\n",
      "- [TRAIN] LOSS : 4.711057343027076e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.0682216927525587e-05 SCORE : 1.0\n",
      "[750/1000]\n",
      "- [TRAIN] LOSS : 4.6856274214709025e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.0558596588671207e-05 SCORE : 1.0\n",
      "[751/1000]\n",
      "- [TRAIN] LOSS : 4.660672104566604e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.0431138182175346e-05 SCORE : 1.0\n",
      "[752/1000]\n",
      "- [TRAIN] LOSS : 4.635401016154598e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.0304069039411843e-05 SCORE : 1.0\n",
      "[753/1000]\n",
      "- [TRAIN] LOSS : 4.6108608734761626e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.0185947505524382e-05 SCORE : 1.0\n",
      "[754/1000]\n",
      "- [TRAIN] LOSS : 4.5856706239848994e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 2.0063938791281544e-05 SCORE : 1.0\n",
      "[755/1000]\n",
      "- [TRAIN] LOSS : 4.5615550637497414e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.9935983800678514e-05 SCORE : 1.0\n",
      "[756/1000]\n",
      "- [TRAIN] LOSS : 4.53719337403729e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.9823326510959305e-05 SCORE : 1.0\n",
      "[757/1000]\n",
      "- [TRAIN] LOSS : 4.512239476955276e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.9702549252542667e-05 SCORE : 1.0\n",
      "[758/1000]\n",
      "- [TRAIN] LOSS : 4.488222132042413e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.958213215402793e-05 SCORE : 1.0\n",
      "[759/1000]\n",
      "- [TRAIN] LOSS : 4.464069590742131e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.9462057025521062e-05 SCORE : 1.0\n",
      "[760/1000]\n",
      "- [TRAIN] LOSS : 4.44004787520195e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.934662213898264e-05 SCORE : 1.0\n",
      "[761/1000]\n",
      "- [TRAIN] LOSS : 4.4160942656566883e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.9227309167035855e-05 SCORE : 1.0\n",
      "[762/1000]\n",
      "- [TRAIN] LOSS : 4.392351204134886e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.9112630980089307e-05 SCORE : 1.0\n",
      "[763/1000]\n",
      "- [TRAIN] LOSS : 4.369008977139149e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.899406561278738e-05 SCORE : 1.0\n",
      "[764/1000]\n",
      "- [TRAIN] LOSS : 4.345360998235669e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.8880291463574395e-05 SCORE : 1.0\n",
      "[765/1000]\n",
      "- [TRAIN] LOSS : 4.322756118805652e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.8762702893582173e-05 SCORE : 1.0\n",
      "[766/1000]\n",
      "- [TRAIN] LOSS : 4.299123909529751e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.8649743651621975e-05 SCORE : 1.0\n",
      "[767/1000]\n",
      "- [TRAIN] LOSS : 4.276617770907857e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.8541401004767977e-05 SCORE : 1.0\n",
      "[768/1000]\n",
      "- [TRAIN] LOSS : 4.253052636866212e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.8429172996548004e-05 SCORE : 1.0\n",
      "[769/1000]\n",
      "- [TRAIN] LOSS : 4.230410468153423e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.8313066902919672e-05 SCORE : 1.0\n",
      "[770/1000]\n",
      "- [TRAIN] LOSS : 4.207757046970073e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.8201584680355154e-05 SCORE : 1.0\n",
      "[771/1000]\n",
      "- [TRAIN] LOSS : 4.185026849275649e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.809041168598924e-05 SCORE : 1.0\n",
      "[772/1000]\n",
      "- [TRAIN] LOSS : 4.163020624522081e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.7979558833758347e-05 SCORE : 1.0\n",
      "[773/1000]\n",
      "- [TRAIN] LOSS : 4.1408795570734786e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.7873318938654847e-05 SCORE : 1.0\n",
      "[774/1000]\n",
      "- [TRAIN] LOSS : 4.118607583020801e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.7763142750482075e-05 SCORE : 1.0\n",
      "[775/1000]\n",
      "- [TRAIN] LOSS : 4.096270211246317e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.766181958373636e-05 SCORE : 1.0\n",
      "[776/1000]\n",
      "- [TRAIN] LOSS : 4.074507635070606e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.7552269127918407e-05 SCORE : 1.0\n",
      "[777/1000]\n",
      "- [TRAIN] LOSS : 4.052738500427545e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.7438800568925217e-05 SCORE : 1.0\n",
      "[778/1000]\n",
      "- [TRAIN] LOSS : 4.030965934968359e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.7338401448796503e-05 SCORE : 1.0\n",
      "[779/1000]\n",
      "- [TRAIN] LOSS : 4.008984453523428e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.723406239761971e-05 SCORE : 1.0\n",
      "[780/1000]\n",
      "- [TRAIN] LOSS : 3.9882567509468776e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.713004894554615e-05 SCORE : 1.0\n",
      "[781/1000]\n",
      "- [TRAIN] LOSS : 3.966933455659374e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.7030642993631773e-05 SCORE : 1.0\n",
      "[782/1000]\n",
      "- [TRAIN] LOSS : 3.9460830673003024e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.6927331671467982e-05 SCORE : 1.0\n",
      "[783/1000]\n",
      "- [TRAIN] LOSS : 3.924440857695622e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.6815851267892867e-05 SCORE : 1.0\n",
      "[784/1000]\n",
      "- [TRAIN] LOSS : 3.9035209990995805e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.6721676729503088e-05 SCORE : 1.0\n",
      "[785/1000]\n",
      "- [TRAIN] LOSS : 3.883247669970539e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.661930036789272e-05 SCORE : 1.0\n",
      "[786/1000]\n",
      "- [TRAIN] LOSS : 3.8623070445788064e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.6521482393727638e-05 SCORE : 1.0\n",
      "[787/1000]\n",
      "- [TRAIN] LOSS : 3.841428795365371e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.641545895836316e-05 SCORE : 1.0\n",
      "[788/1000]\n",
      "- [TRAIN] LOSS : 3.821137498663221e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.632251041883137e-05 SCORE : 1.0\n",
      "[789/1000]\n",
      "- [TRAIN] LOSS : 3.800574035671566e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.622132185730152e-05 SCORE : 1.0\n",
      "[790/1000]\n",
      "- [TRAIN] LOSS : 3.780529666780947e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.6128991774166934e-05 SCORE : 1.0\n",
      "[791/1000]\n",
      "- [TRAIN] LOSS : 3.760284072187561e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.603270720806904e-05 SCORE : 1.0\n",
      "[792/1000]\n",
      "- [TRAIN] LOSS : 3.739702636570049e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.592819535289891e-05 SCORE : 1.0\n",
      "[793/1000]\n",
      "- [TRAIN] LOSS : 3.7202963767413166e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.58324655785691e-05 SCORE : 1.0\n",
      "[794/1000]\n",
      "- [TRAIN] LOSS : 3.7005586818850134e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.5741316019557416e-05 SCORE : 1.0\n",
      "[795/1000]\n",
      "- [TRAIN] LOSS : 3.680813390221576e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.5646221072529443e-05 SCORE : 1.0\n",
      "[796/1000]\n",
      "- [TRAIN] LOSS : 3.6611266599114366e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.5555673599010333e-05 SCORE : 1.0\n",
      "[797/1000]\n",
      "- [TRAIN] LOSS : 3.641301721775866e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.546114799566567e-05 SCORE : 1.0\n",
      "[798/1000]\n",
      "- [TRAIN] LOSS : 3.622454614237035e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.5366900697699748e-05 SCORE : 1.0\n",
      "[799/1000]\n",
      "- [TRAIN] LOSS : 3.603068807933596e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.526872074464336e-05 SCORE : 1.0\n",
      "[800/1000]\n",
      "- [TRAIN] LOSS : 3.583615966817888e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.5179311958490871e-05 SCORE : 1.0\n",
      "[801/1000]\n",
      "- [TRAIN] LOSS : 3.5648432736302814e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.5086751773196738e-05 SCORE : 1.0\n",
      "[802/1000]\n",
      "- [TRAIN] LOSS : 3.5457238406403725e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.4990465388109442e-05 SCORE : 1.0\n",
      "[803/1000]\n",
      "- [TRAIN] LOSS : 3.527311183562334e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.4903001101629343e-05 SCORE : 1.0\n",
      "[804/1000]\n",
      "- [TRAIN] LOSS : 3.5080806659001006e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.4811467735853512e-05 SCORE : 1.0\n",
      "[805/1000]\n",
      "- [TRAIN] LOSS : 3.48927375297434e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.4724349966854788e-05 SCORE : 1.0\n",
      "[806/1000]\n",
      "- [TRAIN] LOSS : 3.4712047989968494e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.4637394997407682e-05 SCORE : 1.0\n",
      "[807/1000]\n",
      "- [TRAIN] LOSS : 3.452838414988138e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.4550730156770442e-05 SCORE : 1.0\n",
      "[808/1000]\n",
      "- [TRAIN] LOSS : 3.434627327199754e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.4460149031947367e-05 SCORE : 1.0\n",
      "[809/1000]\n",
      "- [TRAIN] LOSS : 3.4162904739787336e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.4369837117556017e-05 SCORE : 1.0\n",
      "[810/1000]\n",
      "- [TRAIN] LOSS : 3.397993858319145e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.4279677998274565e-05 SCORE : 1.0\n",
      "[811/1000]\n",
      "- [TRAIN] LOSS : 3.380439127593288e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.4198226381267887e-05 SCORE : 1.0\n",
      "[812/1000]\n",
      "- [TRAIN] LOSS : 3.362323716121157e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.4116952115728054e-05 SCORE : 1.0\n",
      "[813/1000]\n",
      "- [TRAIN] LOSS : 3.3446953719046884e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.4018825822859071e-05 SCORE : 1.0\n",
      "[814/1000]\n",
      "- [TRAIN] LOSS : 3.32689377905303e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.3942192708782386e-05 SCORE : 1.0\n",
      "[815/1000]\n",
      "- [TRAIN] LOSS : 3.308917164051511e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.3857164958608337e-05 SCORE : 1.0\n",
      "[816/1000]\n",
      "- [TRAIN] LOSS : 3.291757431927383e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.377661192236701e-05 SCORE : 1.0\n",
      "[817/1000]\n",
      "- [TRAIN] LOSS : 3.2742369588352936e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.3696271707885899e-05 SCORE : 1.0\n",
      "[818/1000]\n",
      "- [TRAIN] LOSS : 3.257013551976545e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.3603332263301127e-05 SCORE : 1.0\n",
      "[819/1000]\n",
      "- [TRAIN] LOSS : 3.240214871564401e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.3531911463360302e-05 SCORE : 1.0\n",
      "[820/1000]\n",
      "- [TRAIN] LOSS : 3.222268206728687e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.343939220532775e-05 SCORE : 1.0\n",
      "[821/1000]\n",
      "- [TRAIN] LOSS : 3.2055459213451184e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.3364110600377899e-05 SCORE : 1.0\n",
      "[822/1000]\n",
      "- [TRAIN] LOSS : 3.188266161184098e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.328478720097337e-05 SCORE : 1.0\n",
      "[823/1000]\n",
      "- [TRAIN] LOSS : 3.1720089661272745e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.3205654795456212e-05 SCORE : 1.0\n",
      "[824/1000]\n",
      "- [TRAIN] LOSS : 3.1555398764895573e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.3122526979714166e-05 SCORE : 1.0\n",
      "[825/1000]\n",
      "- [TRAIN] LOSS : 3.137793861343299e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.3048129403614439e-05 SCORE : 1.0\n",
      "[826/1000]\n",
      "- [TRAIN] LOSS : 3.1219371546992785e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.2969704584975261e-05 SCORE : 1.0\n",
      "[827/1000]\n",
      "- [TRAIN] LOSS : 3.1053329242543746e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.2891496226075105e-05 SCORE : 1.0\n",
      "[828/1000]\n",
      "- [TRAIN] LOSS : 3.0887038166030026e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.2813509783882182e-05 SCORE : 1.0\n",
      "[829/1000]\n",
      "- [TRAIN] LOSS : 3.0729770666463686e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.2740004422084894e-05 SCORE : 1.0\n",
      "[830/1000]\n",
      "- [TRAIN] LOSS : 3.056634735306337e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.2662457265832927e-05 SCORE : 1.0\n",
      "[831/1000]\n",
      "- [TRAIN] LOSS : 3.0402066815642887e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.258516113011865e-05 SCORE : 1.0\n",
      "[832/1000]\n",
      "- [TRAIN] LOSS : 3.0243540095398203e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.2508071449701674e-05 SCORE : 1.0\n",
      "[833/1000]\n",
      "- [TRAIN] LOSS : 3.0084098751912177e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.24269299703883e-05 SCORE : 1.0\n",
      "[834/1000]\n",
      "- [TRAIN] LOSS : 2.9927109305087168e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.2358813364699017e-05 SCORE : 1.0\n",
      "[835/1000]\n",
      "- [TRAIN] LOSS : 2.9764619385888283e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.2286615856282879e-05 SCORE : 1.0\n",
      "[836/1000]\n",
      "- [TRAIN] LOSS : 2.96090461233689e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.2218887604831252e-05 SCORE : 1.0\n",
      "[837/1000]\n",
      "- [TRAIN] LOSS : 2.9451941221244244e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.2142884770582896e-05 SCORE : 1.0\n",
      "[838/1000]\n",
      "- [TRAIN] LOSS : 2.929995717851044e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.2071351193299051e-05 SCORE : 1.0\n",
      "[839/1000]\n",
      "- [TRAIN] LOSS : 2.9145787998964402e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.1995777640549932e-05 SCORE : 1.0\n",
      "[840/1000]\n",
      "- [TRAIN] LOSS : 2.89907188996747e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.192468153021764e-05 SCORE : 1.0\n",
      "[841/1000]\n",
      "- [TRAIN] LOSS : 2.8838086463009757e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.1849531801999547e-05 SCORE : 1.0\n",
      "[842/1000]\n",
      "- [TRAIN] LOSS : 2.8683879109949987e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.1774568520195317e-05 SCORE : 1.0\n",
      "[843/1000]\n",
      "- [TRAIN] LOSS : 2.85360052000922e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.1708361853379756e-05 SCORE : 1.0\n",
      "[844/1000]\n",
      "- [TRAIN] LOSS : 2.838200589394546e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.1642355275398586e-05 SCORE : 1.0\n",
      "[845/1000]\n",
      "- [TRAIN] LOSS : 2.823302866595946e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.156376220023958e-05 SCORE : 1.0\n",
      "[846/1000]\n",
      "- [TRAIN] LOSS : 2.8087089933453375e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.1493897545733489e-05 SCORE : 1.0\n",
      "[847/1000]\n",
      "- [TRAIN] LOSS : 2.79423039349543e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.1432797691668384e-05 SCORE : 1.0\n",
      "[848/1000]\n",
      "- [TRAIN] LOSS : 2.7793379634507193e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.1363375051587354e-05 SCORE : 1.0\n",
      "[849/1000]\n",
      "- [TRAIN] LOSS : 2.7647510200444634e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.1298418939986732e-05 SCORE : 1.0\n",
      "[850/1000]\n",
      "- [TRAIN] LOSS : 2.7500096292796014e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.1233666555199306e-05 SCORE : 1.0\n",
      "[851/1000]\n",
      "- [TRAIN] LOSS : 2.7350464910745763e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.1156327673234046e-05 SCORE : 1.0\n",
      "[852/1000]\n",
      "- [TRAIN] LOSS : 2.7208365660650696e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.1096179150626995e-05 SCORE : 1.0\n",
      "[853/1000]\n",
      "- [TRAIN] LOSS : 2.7065343854499384e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.1023456863767933e-05 SCORE : 1.0\n",
      "[854/1000]\n",
      "- [TRAIN] LOSS : 2.6924705606587748e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.0965248293359764e-05 SCORE : 1.0\n",
      "[855/1000]\n",
      "- [TRAIN] LOSS : 2.6778499255265666e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.0900420420512091e-05 SCORE : 1.0\n",
      "[856/1000]\n",
      "- [TRAIN] LOSS : 2.6643236828426274e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.083577808458358e-05 SCORE : 1.0\n",
      "[857/1000]\n",
      "- [TRAIN] LOSS : 2.6501261774885483e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.0775559530884493e-05 SCORE : 1.0\n",
      "[858/1000]\n",
      "- [TRAIN] LOSS : 2.6360398098606514e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.0715511052694637e-05 SCORE : 1.0\n",
      "[859/1000]\n",
      "- [TRAIN] LOSS : 2.622123179207847e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.0659866347850766e-05 SCORE : 1.0\n",
      "[860/1000]\n",
      "- [TRAIN] LOSS : 2.6086376717810505e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.0591596947051585e-05 SCORE : 1.0\n",
      "[861/1000]\n",
      "- [TRAIN] LOSS : 2.5953281667372925e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.0527754966460634e-05 SCORE : 1.0\n",
      "[862/1000]\n",
      "- [TRAIN] LOSS : 2.5812087945572177e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.0476853276486509e-05 SCORE : 1.0\n",
      "[863/1000]\n",
      "- [TRAIN] LOSS : 2.5677216424608356e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.0413323252578266e-05 SCORE : 1.0\n",
      "[864/1000]\n",
      "- [TRAIN] LOSS : 2.5542032340632028e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.0358467079640832e-05 SCORE : 1.0\n",
      "[865/1000]\n",
      "- [TRAIN] LOSS : 2.541062599448196e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.0299506357114296e-05 SCORE : 1.0\n",
      "[866/1000]\n",
      "- [TRAIN] LOSS : 2.5274309008535864e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.0244949407933746e-05 SCORE : 1.0\n",
      "[867/1000]\n",
      "- [TRAIN] LOSS : 2.5146347676733665e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.0182046935369726e-05 SCORE : 1.0\n",
      "[868/1000]\n",
      "- [TRAIN] LOSS : 2.5013463502748185e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.012352186080534e-05 SCORE : 1.0\n",
      "[869/1000]\n",
      "- [TRAIN] LOSS : 2.4882275460590285e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.0060900422104169e-05 SCORE : 1.0\n",
      "[870/1000]\n",
      "- [TRAIN] LOSS : 2.4746840381340007e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 1.001119198917877e-05 SCORE : 1.0\n",
      "[871/1000]\n",
      "- [TRAIN] LOSS : 2.4617646709480647e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 9.95735899778083e-06 SCORE : 1.0\n",
      "[872/1000]\n",
      "- [TRAIN] LOSS : 2.4489476876018063e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 9.890914043353405e-06 SCORE : 1.0\n",
      "[873/1000]\n",
      "- [TRAIN] LOSS : 2.4359689859920763e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 9.837372090260033e-06 SCORE : 1.0\n",
      "[874/1000]\n",
      "- [TRAIN] LOSS : 2.423092046733978e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 9.783959285414312e-06 SCORE : 1.0\n",
      "[875/1000]\n",
      "- [TRAIN] LOSS : 2.410573948610464e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 9.734946615935769e-06 SCORE : 1.0\n",
      "[876/1000]\n",
      "- [TRAIN] LOSS : 2.3979640900506638e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 9.681823030405212e-06 SCORE : 1.0\n",
      "[877/1000]\n",
      "- [TRAIN] LOSS : 2.385526408943406e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 9.628839507058728e-06 SCORE : 1.0\n",
      "[878/1000]\n",
      "- [TRAIN] LOSS : 2.372928732559861e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 9.567492270434741e-06 SCORE : 1.0\n",
      "[879/1000]\n",
      "- [TRAIN] LOSS : 2.3605668047821382e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 9.510544259683229e-06 SCORE : 1.0\n",
      "[880/1000]\n",
      "- [TRAIN] LOSS : 2.348179087776872e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 9.457994565309491e-06 SCORE : 1.0\n",
      "[881/1000]\n",
      "- [TRAIN] LOSS : 2.335897769019842e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 9.405579476151615e-06 SCORE : 1.0\n",
      "[882/1000]\n",
      "- [TRAIN] LOSS : 2.323513917367058e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 9.353298992209602e-06 SCORE : 1.0\n",
      "[883/1000]\n",
      "- [TRAIN] LOSS : 2.311229326955476e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 9.305404091719538e-06 SCORE : 1.0\n",
      "[884/1000]\n",
      "- [TRAIN] LOSS : 2.299306968072617e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 9.249116374121513e-06 SCORE : 1.0\n",
      "[885/1000]\n",
      "- [TRAIN] LOSS : 2.287421418461438e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 9.197232429869473e-06 SCORE : 1.0\n",
      "[886/1000]\n",
      "- [TRAIN] LOSS : 2.275308826129832e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 9.149739526037592e-06 SCORE : 1.0\n",
      "[887/1000]\n",
      "- [TRAIN] LOSS : 2.2634277355690654e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 9.098122063733172e-06 SCORE : 1.0\n",
      "[888/1000]\n",
      "- [TRAIN] LOSS : 2.2513177959303397e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 9.0338589870953e-06 SCORE : 1.0\n",
      "[889/1000]\n",
      "- [TRAIN] LOSS : 2.2399671833126275e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 8.986755346995778e-06 SCORE : 1.0\n",
      "[890/1000]\n",
      "- [TRAIN] LOSS : 2.22839069768573e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 8.939789040596224e-06 SCORE : 1.0\n",
      "[891/1000]\n",
      "- [TRAIN] LOSS : 2.216188103274261e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 8.884422641131096e-06 SCORE : 1.0\n",
      "[892/1000]\n",
      "- [TRAIN] LOSS : 2.204342440058503e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 8.837689165375195e-06 SCORE : 1.0\n",
      "[893/1000]\n",
      "- [TRAIN] LOSS : 2.1932531391636683e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 8.791101208771579e-06 SCORE : 1.0\n",
      "[894/1000]\n",
      "- [TRAIN] LOSS : 2.181675673303592e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 8.744637852942105e-06 SCORE : 1.0\n",
      "[895/1000]\n",
      "- [TRAIN] LOSS : 2.1702590970562596e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 8.69403356773546e-06 SCORE : 1.0\n",
      "[896/1000]\n",
      "- [TRAIN] LOSS : 2.1590078606297742e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 8.643551154818852e-06 SCORE : 1.0\n",
      "[897/1000]\n",
      "- [TRAIN] LOSS : 2.147392408207654e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 8.593192433181684e-06 SCORE : 1.0\n",
      "[898/1000]\n",
      "- [TRAIN] LOSS : 2.1363365085057416e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 8.547202924091835e-06 SCORE : 1.0\n",
      "[899/1000]\n",
      "- [TRAIN] LOSS : 2.1249114575362506e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 8.497074304614216e-06 SCORE : 1.0\n",
      "[900/1000]\n",
      "- [TRAIN] LOSS : 2.113780036931227e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 8.447061190963723e-06 SCORE : 1.0\n",
      "[901/1000]\n",
      "- [TRAIN] LOSS : 2.1032150951012023e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 8.401452760153916e-06 SCORE : 1.0\n",
      "[902/1000]\n",
      "- [TRAIN] LOSS : 2.0919428139778676e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 8.352584700332955e-06 SCORE : 1.0\n",
      "[903/1000]\n",
      "- [TRAIN] LOSS : 2.0812044112972217e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 8.299854016513564e-06 SCORE : 1.0\n",
      "[904/1000]\n",
      "- [TRAIN] LOSS : 2.0706303694674312e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 8.242963303928263e-06 SCORE : 1.0\n",
      "[905/1000]\n",
      "- [TRAIN] LOSS : 2.0603545256866102e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 8.18178705230821e-06 SCORE : 1.0\n",
      "[906/1000]\n",
      "- [TRAIN] LOSS : 2.0488956629883938e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 8.133278242894448e-06 SCORE : 1.0\n",
      "[907/1000]\n",
      "- [TRAIN] LOSS : 2.038001755661551e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 8.088919457804877e-06 SCORE : 1.0\n",
      "[908/1000]\n",
      "- [TRAIN] LOSS : 2.0278593069633644e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 8.040196007641498e-06 SCORE : 1.0\n",
      "[909/1000]\n",
      "- [TRAIN] LOSS : 2.017496880550122e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.991415259311907e-06 SCORE : 1.0\n",
      "[910/1000]\n",
      "- [TRAIN] LOSS : 2.0071911687106574e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.942593583720736e-06 SCORE : 1.0\n",
      "[911/1000]\n",
      "- [TRAIN] LOSS : 1.996622313527041e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.889474545663688e-06 SCORE : 1.0\n",
      "[912/1000]\n",
      "- [TRAIN] LOSS : 1.9861885675709345e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.840581019991077e-06 SCORE : 1.0\n",
      "[913/1000]\n",
      "- [TRAIN] LOSS : 1.9764907822011286e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.800202183716465e-06 SCORE : 1.0\n",
      "[914/1000]\n",
      "- [TRAIN] LOSS : 1.965962237843794e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.75132230046438e-06 SCORE : 1.0\n",
      "[915/1000]\n",
      "- [TRAIN] LOSS : 1.956057926438209e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.706715223321225e-06 SCORE : 1.0\n",
      "[916/1000]\n",
      "- [TRAIN] LOSS : 1.9456642626715216e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.657889000256546e-06 SCORE : 1.0\n",
      "[917/1000]\n",
      "- [TRAIN] LOSS : 1.935373421070431e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.617597930220654e-06 SCORE : 1.0\n",
      "[918/1000]\n",
      "- [TRAIN] LOSS : 1.9259164383179774e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.568841738248011e-06 SCORE : 1.0\n",
      "[919/1000]\n",
      "- [TRAIN] LOSS : 1.9161881394009266e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.528670266765403e-06 SCORE : 1.0\n",
      "[920/1000]\n",
      "- [TRAIN] LOSS : 1.90592694480074e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.48855291021755e-06 SCORE : 1.0\n",
      "[921/1000]\n",
      "- [TRAIN] LOSS : 1.89658562451061e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.444260518241208e-06 SCORE : 1.0\n",
      "[922/1000]\n",
      "- [TRAIN] LOSS : 1.886387427576766e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.395787633868167e-06 SCORE : 1.0\n",
      "[923/1000]\n",
      "- [TRAIN] LOSS : 1.8767833896365322e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.351634394581197e-06 SCORE : 1.0\n",
      "[924/1000]\n",
      "- [TRAIN] LOSS : 1.86691179856603e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.311803528864402e-06 SCORE : 1.0\n",
      "[925/1000]\n",
      "- [TRAIN] LOSS : 1.857699467361979e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.263546194735682e-06 SCORE : 1.0\n",
      "[926/1000]\n",
      "- [TRAIN] LOSS : 1.847837473986955e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.219629424071172e-06 SCORE : 1.0\n",
      "[927/1000]\n",
      "- [TRAIN] LOSS : 1.8385137890517297e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.180068223533453e-06 SCORE : 1.0\n",
      "[928/1000]\n",
      "- [TRAIN] LOSS : 1.82874436328954e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.1405993367079645e-06 SCORE : 1.0\n",
      "[929/1000]\n",
      "- [TRAIN] LOSS : 1.8195146670526203e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.101219580363249e-06 SCORE : 1.0\n",
      "[930/1000]\n",
      "- [TRAIN] LOSS : 1.8100989766228144e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.057664788590046e-06 SCORE : 1.0\n",
      "[931/1000]\n",
      "- [TRAIN] LOSS : 1.8008324193235443e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 7.018475116638001e-06 SCORE : 1.0\n",
      "[932/1000]\n",
      "- [TRAIN] LOSS : 1.7915799642448998e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.983633738855133e-06 SCORE : 1.0\n",
      "[933/1000]\n",
      "- [TRAIN] LOSS : 1.7824820613693897e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.9446473389689345e-06 SCORE : 1.0\n",
      "[934/1000]\n",
      "- [TRAIN] LOSS : 1.7728071485281463e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.901494543853914e-06 SCORE : 1.0\n",
      "[935/1000]\n",
      "- [TRAIN] LOSS : 1.7641387292618067e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.862693680886878e-06 SCORE : 1.0\n",
      "[936/1000]\n",
      "- [TRAIN] LOSS : 1.7546997481885126e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.815476353949634e-06 SCORE : 1.0\n",
      "[937/1000]\n",
      "- [TRAIN] LOSS : 1.745937536017866e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.7811379267368466e-06 SCORE : 1.0\n",
      "[938/1000]\n",
      "- [TRAIN] LOSS : 1.7367994473715953e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.74264492772636e-06 SCORE : 1.0\n",
      "[939/1000]\n",
      "- [TRAIN] LOSS : 1.7276838522977618e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.6999864429817535e-06 SCORE : 1.0\n",
      "[940/1000]\n",
      "- [TRAIN] LOSS : 1.718980801494278e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.66168989482685e-06 SCORE : 1.0\n",
      "[941/1000]\n",
      "- [TRAIN] LOSS : 1.7099751643298885e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.627758011745755e-06 SCORE : 1.0\n",
      "[942/1000]\n",
      "- [TRAIN] LOSS : 1.7012555114585364e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.593931630050065e-06 SCORE : 1.0\n",
      "[943/1000]\n",
      "- [TRAIN] LOSS : 1.6923639135610654e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.55593703413615e-06 SCORE : 1.0\n",
      "[944/1000]\n",
      "- [TRAIN] LOSS : 1.683886907560211e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.522302101075184e-06 SCORE : 1.0\n",
      "[945/1000]\n",
      "- [TRAIN] LOSS : 1.675036123237482e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.4845085034903605e-06 SCORE : 1.0\n",
      "[946/1000]\n",
      "- [TRAIN] LOSS : 1.666865590424196e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.442565336328698e-06 SCORE : 1.0\n",
      "[947/1000]\n",
      "- [TRAIN] LOSS : 1.6580680797536235e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.4049904722196516e-06 SCORE : 1.0\n",
      "[948/1000]\n",
      "- [TRAIN] LOSS : 1.6496238825109482e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.376038527378114e-06 SCORE : 1.0\n",
      "[949/1000]\n",
      "- [TRAIN] LOSS : 1.64113715123272e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.3386623878614046e-06 SCORE : 1.0\n",
      "[950/1000]\n",
      "- [TRAIN] LOSS : 1.632934299777844e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.297126674326137e-06 SCORE : 1.0\n",
      "[951/1000]\n",
      "- [TRAIN] LOSS : 1.624627709083547e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.2642079683428165e-06 SCORE : 1.0\n",
      "[952/1000]\n",
      "- [TRAIN] LOSS : 1.616211079635832e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.227117410162464e-06 SCORE : 1.0\n",
      "[953/1000]\n",
      "- [TRAIN] LOSS : 1.6075496849528765e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.181610842759255e-06 SCORE : 1.0\n",
      "[954/1000]\n",
      "- [TRAIN] LOSS : 1.599569220110829e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.148976353870239e-06 SCORE : 1.0\n",
      "[955/1000]\n",
      "- [TRAIN] LOSS : 1.5910864173444377e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.116435088188155e-06 SCORE : 1.0\n",
      "[956/1000]\n",
      "- [TRAIN] LOSS : 1.5823542665000583e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.0839806792500895e-06 SCORE : 1.0\n",
      "[957/1000]\n",
      "- [TRAIN] LOSS : 1.5742994289919603e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.043095254426589e-06 SCORE : 1.0\n",
      "[958/1000]\n",
      "- [TRAIN] LOSS : 1.5663311892745292e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 6.015079179633176e-06 SCORE : 1.0\n",
      "[959/1000]\n",
      "- [TRAIN] LOSS : 1.5583193923400056e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.9786407291539945e-06 SCORE : 1.0\n",
      "[960/1000]\n",
      "- [TRAIN] LOSS : 1.550594213818436e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.946556939306902e-06 SCORE : 1.0\n",
      "[961/1000]\n",
      "- [TRAIN] LOSS : 1.5426331591091486e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.914577741350513e-06 SCORE : 1.0\n",
      "[962/1000]\n",
      "- [TRAIN] LOSS : 1.534967812707085e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.882698133063968e-06 SCORE : 1.0\n",
      "[963/1000]\n",
      "- [TRAIN] LOSS : 1.5270665661167488e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.850922661920777e-06 SCORE : 1.0\n",
      "[964/1000]\n",
      "- [TRAIN] LOSS : 1.5189895483066115e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.8192408687318675e-06 SCORE : 1.0\n",
      "[965/1000]\n",
      "- [TRAIN] LOSS : 1.5111309734392205e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.779121693194611e-06 SCORE : 1.0\n",
      "[966/1000]\n",
      "- [TRAIN] LOSS : 1.503683385332503e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.7518673202139325e-06 SCORE : 1.0\n",
      "[967/1000]\n",
      "- [TRAIN] LOSS : 1.4958673874490261e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.720441095036222e-06 SCORE : 1.0\n",
      "[968/1000]\n",
      "- [TRAIN] LOSS : 1.4883364908908132e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.680598860635655e-06 SCORE : 1.0\n",
      "[969/1000]\n",
      "- [TRAIN] LOSS : 1.4808298702620152e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.653616426570807e-06 SCORE : 1.0\n",
      "[970/1000]\n",
      "- [TRAIN] LOSS : 1.4729514380936356e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.618207978841383e-06 SCORE : 1.0\n",
      "[971/1000]\n",
      "- [TRAIN] LOSS : 1.4654889052205059e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.582882295129821e-06 SCORE : 1.0\n",
      "[972/1000]\n",
      "- [TRAIN] LOSS : 1.457450014186179e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.556158157560276e-06 SCORE : 1.0\n",
      "[973/1000]\n",
      "- [TRAIN] LOSS : 1.4498250177691969e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.520999366126489e-06 SCORE : 1.0\n",
      "[974/1000]\n",
      "- [TRAIN] LOSS : 1.4425465527286482e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.494428023666842e-06 SCORE : 1.0\n",
      "[975/1000]\n",
      "- [TRAIN] LOSS : 1.435020745551204e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.463682555273408e-06 SCORE : 1.0\n",
      "[976/1000]\n",
      "- [TRAIN] LOSS : 1.427914360697792e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.433026217360748e-06 SCORE : 1.0\n",
      "[977/1000]\n",
      "- [TRAIN] LOSS : 1.4205635617751492e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.402450824476546e-06 SCORE : 1.0\n",
      "[978/1000]\n",
      "- [TRAIN] LOSS : 1.4135018192165364e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.371973202272784e-06 SCORE : 1.0\n",
      "[979/1000]\n",
      "- [TRAIN] LOSS : 1.4063375879737174e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.3458447837329e-06 SCORE : 1.0\n",
      "[980/1000]\n",
      "- [TRAIN] LOSS : 1.3989287872896562e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.311281711328775e-06 SCORE : 1.0\n",
      "[981/1000]\n",
      "- [TRAIN] LOSS : 1.3919384893294287e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.276802312437212e-06 SCORE : 1.0\n",
      "[982/1000]\n",
      "- [TRAIN] LOSS : 1.384510745891829e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.2466684792307205e-06 SCORE : 1.0\n",
      "[983/1000]\n",
      "- [TRAIN] LOSS : 1.3774232400010078e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.220855200605001e-06 SCORE : 1.0\n",
      "[984/1000]\n",
      "- [TRAIN] LOSS : 1.370619060657595e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.195120593270985e-06 SCORE : 1.0\n",
      "[985/1000]\n",
      "- [TRAIN] LOSS : 1.3637047869805327e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.156701718078693e-06 SCORE : 1.0\n",
      "[986/1000]\n",
      "- [TRAIN] LOSS : 1.3565483502336267e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.131134912517155e-06 SCORE : 1.0\n",
      "[987/1000]\n",
      "- [TRAIN] LOSS : 1.3492785689726992e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.101377610117197e-06 SCORE : 1.0\n",
      "[988/1000]\n",
      "- [TRAIN] LOSS : 1.3428144149606345e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.0759604164341e-06 SCORE : 1.0\n",
      "[989/1000]\n",
      "- [TRAIN] LOSS : 1.3358470406880466e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.046372280048672e-06 SCORE : 1.0\n",
      "[990/1000]\n",
      "- [TRAIN] LOSS : 1.3285697984125969e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 5.0211174311698414e-06 SCORE : 1.0\n",
      "[991/1000]\n",
      "- [TRAIN] LOSS : 1.3217723316453581e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.987410193280084e-06 SCORE : 1.0\n",
      "[992/1000]\n",
      "- [TRAIN] LOSS : 1.3145198667845963e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.962282218912151e-06 SCORE : 1.0\n",
      "[993/1000]\n",
      "- [TRAIN] LOSS : 1.3080124795629268e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.93340576213086e-06 SCORE : 1.0\n",
      "[994/1000]\n",
      "- [TRAIN] LOSS : 1.3013884546985031e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.900519797956804e-06 SCORE : 1.0\n",
      "[995/1000]\n",
      "- [TRAIN] LOSS : 1.2947860764395753e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.876213097304571e-06 SCORE : 1.0\n",
      "[996/1000]\n",
      "- [TRAIN] LOSS : 1.2883394990442159e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.847729542234447e-06 SCORE : 1.0\n",
      "[997/1000]\n",
      "- [TRAIN] LOSS : 1.2820516101581032e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.8235829126497265e-06 SCORE : 1.0\n",
      "[998/1000]\n",
      "- [TRAIN] LOSS : 1.2751266543394498e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.795246240973938e-06 SCORE : 1.0\n",
      "[999/1000]\n",
      "- [TRAIN] LOSS : 1.2688816702342996e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.771235126099782e-06 SCORE : 1.0\n",
      "[1000/1000]\n",
      "- [TRAIN] LOSS : 1.2625268261167043e-05 SCORE : 1.0\n",
      "- [VALID] LOSS : 4.743039426102769e-06 SCORE : 1.0\n"
     ]
    }
   ],
   "source": [
    "## 학습의 효과 확인, 손실값과 성능평가값 저장 필요 , 검증기능을 \n",
    "LOSS_HISTORY, SCORE_HISTORY = [[], []], [[], []]\n",
    "CNT = len(trainDL)\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "\n",
    "    # 학습 모드로 모델 설정\n",
    "    model.train()\n",
    "    \n",
    "    # 배치 크기 만큼 데이터 로딩해서 학습 진행\n",
    "    loss_total, score_total = 0, 0\n",
    "    for featureTS, targetTS in trainDL:\n",
    "\n",
    "        # 학습 진행\n",
    "        pre_y = model(featureTS)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = crossLoss(pre_y, targetTS)\n",
    "        loss_total += loss.item()\n",
    "\n",
    "        # 성능 평가 계산\n",
    "        score = BinaryF1Score()(pre_y, targetTS) \n",
    "        score_total += score\n",
    "\n",
    "        # 최적화 진행\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # 에포크 당 검증 기능\n",
    "    # 모델 검증 모드 설정 >> 검증이기에 업데이트 불필요\n",
    "    model.eval() \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # 검증 데이터셋\n",
    "        val_featrueTS = torch.FloatTensor(valDS.featureDF.values)\n",
    "        val_targetTS = torch.FloatTensor(valDS.targetDF.values)\n",
    "\n",
    "        # 추론 / 평가 \n",
    "        pre_val = model(val_featrueTS)\n",
    "        \n",
    "        # 손실\n",
    "        loss_val = crossLoss(pre_val, val_targetTS)\n",
    "        \n",
    "        # 성능평가\n",
    "        score_val = BinaryF1Score()(pre_y, targetTS)\n",
    "\n",
    "    \n",
    "    # 에포크 당 손실값과 성능평가값 저장\n",
    "    LOSS_HISTORY[0].append(loss_total/CNT)\n",
    "    SCORE_HISTORY[0].append(score_total/CNT) \n",
    "\n",
    "    LOSS_HISTORY[1].append(loss_val)\n",
    "    SCORE_HISTORY[1].append(score_val)\n",
    "\n",
    "    # 돌아가는거 보기위해\n",
    "    print(f'[{epoch+1}/{EPOCH}]\\n- [TRAIN] LOSS : {LOSS_HISTORY[0][-1]} SCORE : {SCORE_HISTORY[0][-1]}')\n",
    "    print(f'- [VALID] LOSS : {LOSS_HISTORY[1][-1]} SCORE : {SCORE_HISTORY[1][-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습 결과 체크 => 학습과 검증의 loss변화, 성능 변화, 그래프까지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습 후 loss 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fg, axes=plt.subplots(1,2, figsize=(10,5), sharex=True, sharey=True)\n",
    "axes[0].plot(range(1, EPOCH+1), LOSS_HISTORY[0][:EPOCH], label='Train')\n",
    "axes[0].plot(range(1, EPOCH+1), LOSS_HISTORY[1][:EPOCH], label='Val')\n",
    "axes[0].grid()\n",
    "axes[0].legend()\n",
    "axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "axes[0].set_title(\"LOSS\")\n",
    "\n",
    "axes[1].plot(range(1, EPOCH+1), SCORE_HISTORY[0][:EPOCH], label='Train')\n",
    "axes[1].plot(range(1, EPOCH+1), SCORE_HISTORY[1][:EPOCH], label='Val')\n",
    "axes[1].grid()\n",
    "axes[1].legend()\n",
    "axes[1].set_xlabel(\"Epoch\")\n",
    "axes[1].set_ylabel(\"F1\")\n",
    "axes[1].set_title(\"F1\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[6] 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- [TEST] LOSS : 7.074498626025161e-06 SCORE : 1.0\n"
     ]
    }
   ],
   "source": [
    "# 모델 검증 모드 설정\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # 검증 데이터셋\n",
    "    test_featrueTS=torch.FloatTensor(testDS.featureDF.values).to(DEVICE)\n",
    "    test_targetTS=torch.FloatTensor(testDS.targetDF.values).to(DEVICE)\n",
    "    \n",
    "    # 추론/평가\n",
    "    pre_test=model(test_featrueTS)\n",
    "\n",
    "    # 손실\n",
    "    loss_test=crossLoss(pre_test, test_targetTS)\n",
    "    \n",
    "    # 성능평가\n",
    "    # score_val=F1Score(task='binary')(pre_test, val_targetTS)\n",
    "    score_Test=BinaryF1Score()(pre_test, test_targetTS)\n",
    "    \n",
    "print(f'- [TEST] LOSS : {loss_test.item()} SCORE : {score_Test.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
